{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"16V_SQz4ZxbQkp_aT_EqmFLMe1UybuSBV","authorship_tag":"ABX9TyOGpkNb5RsIe4oAlyeHOXYa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8cc4cb90c6a1451d8b515e7eaa9cedee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_12c3ef3cc9594364b4999d77dd0a48f0","IPY_MODEL_97d2efecfbad43fd9648fe03eb916e2f","IPY_MODEL_9ccaa246e52740dabeacb0f92ce38f04"],"layout":"IPY_MODEL_7fb7ed782dd54ce6b33774b63d7e4ff9"}},"12c3ef3cc9594364b4999d77dd0a48f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35d9715908234e5bb6af7677b0f77b8a","placeholder":"​","style":"IPY_MODEL_1c28f36a19a44617bf1b8ea51d458572","value":"Downloading (…)olve/main/vocab.json: 100%"}},"97d2efecfbad43fd9648fe03eb916e2f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_43be36c363e446edbf92e34d7baa3c3c","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a99fa814f18046e280535626444861b3","value":898823}},"9ccaa246e52740dabeacb0f92ce38f04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9dbd74b6742243d188a45aa28a9ea7c6","placeholder":"​","style":"IPY_MODEL_2a9d4540b3b44539a136bdc85dadc489","value":" 899k/899k [00:00&lt;00:00, 4.75MB/s]"}},"7fb7ed782dd54ce6b33774b63d7e4ff9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35d9715908234e5bb6af7677b0f77b8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c28f36a19a44617bf1b8ea51d458572":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43be36c363e446edbf92e34d7baa3c3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a99fa814f18046e280535626444861b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9dbd74b6742243d188a45aa28a9ea7c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a9d4540b3b44539a136bdc85dadc489":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8a7d2c5ea564035a1d1b61dd7dde4b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a2671ef993a4bdebe6ef1580d57241f","IPY_MODEL_59a2326cefd04cd6890aa3b12e2dd881","IPY_MODEL_5af5c702276d4837b77df32c033bf81d"],"layout":"IPY_MODEL_c614c569d9004dcb9b67d2b7930cdb3f"}},"2a2671ef993a4bdebe6ef1580d57241f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7094ffd221b4437812beae06f6c9411","placeholder":"​","style":"IPY_MODEL_6167ee562f3c429eaeb2d081e91790f2","value":"Downloading (…)olve/main/merges.txt: 100%"}},"59a2326cefd04cd6890aa3b12e2dd881":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8035d09d90e14f78a180c218885d2d2d","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b1284a8ffd84b7c830fd11494b12078","value":456318}},"5af5c702276d4837b77df32c033bf81d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58b2c0f7e38a4671b7cf67f70ebee13c","placeholder":"​","style":"IPY_MODEL_4d22fca97607402197ce7003fd1e1554","value":" 456k/456k [00:00&lt;00:00, 3.65MB/s]"}},"c614c569d9004dcb9b67d2b7930cdb3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7094ffd221b4437812beae06f6c9411":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6167ee562f3c429eaeb2d081e91790f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8035d09d90e14f78a180c218885d2d2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b1284a8ffd84b7c830fd11494b12078":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58b2c0f7e38a4671b7cf67f70ebee13c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d22fca97607402197ce7003fd1e1554":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3c4a5d00e044f0180ac77068e6fde26":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_880a1b7a165a4a7a974122e3d454b7bc","IPY_MODEL_fa451a0a7fc240c3a026c99f5a330457","IPY_MODEL_67e9d3f973fa4a699a5940864570de67"],"layout":"IPY_MODEL_4c99045f018847d68dbdaba0224bda91"}},"880a1b7a165a4a7a974122e3d454b7bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20cbd9d6be884881a190b1b682a87d82","placeholder":"​","style":"IPY_MODEL_e4bb7844942d4a80887580a7cd99385e","value":"Downloading (…)lve/main/config.json: 100%"}},"fa451a0a7fc240c3a026c99f5a330457":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f00c2b56f56243ac89f2252615325c6a","max":1716,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5b2eace6ef424515aa1015622a690c7c","value":1716}},"67e9d3f973fa4a699a5940864570de67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_66257dd2a8314a939f0b44d177a847f4","placeholder":"​","style":"IPY_MODEL_6dcc248bdc794836968702cf45e04698","value":" 1.72k/1.72k [00:00&lt;00:00, 47.2kB/s]"}},"4c99045f018847d68dbdaba0224bda91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20cbd9d6be884881a190b1b682a87d82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4bb7844942d4a80887580a7cd99385e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f00c2b56f56243ac89f2252615325c6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b2eace6ef424515aa1015622a690c7c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"66257dd2a8314a939f0b44d177a847f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dcc248bdc794836968702cf45e04698":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f00a41a6fe3c4f3ba7fa90dd861b47dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_48f14c70a53149b4abcc93f50ad2403f","IPY_MODEL_be9c2fecb2e14e8895898a05d01600a6","IPY_MODEL_9aa61c4034354207b69b71f430c5c3cd"],"layout":"IPY_MODEL_c44ece6052e047468f06181b57a81385"}},"48f14c70a53149b4abcc93f50ad2403f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cbd8adb16484d09b434614551156c19","placeholder":"​","style":"IPY_MODEL_7b118a8fea47460da65051024a73bd52","value":"Downloading model.safetensors: 100%"}},"be9c2fecb2e14e8895898a05d01600a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6cab9f6aa59e44818cadfb3d0a8e8bf0","max":557709915,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5950cffa4f014d4fb7c4eda8c804207d","value":557709915}},"9aa61c4034354207b69b71f430c5c3cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e6ff2d7556044adbeb6d7856cd344ac","placeholder":"​","style":"IPY_MODEL_0f867b7350d44cbebe3b10b8685c1336","value":" 558M/558M [00:08&lt;00:00, 55.5MB/s]"}},"c44ece6052e047468f06181b57a81385":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cbd8adb16484d09b434614551156c19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b118a8fea47460da65051024a73bd52":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6cab9f6aa59e44818cadfb3d0a8e8bf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5950cffa4f014d4fb7c4eda8c804207d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e6ff2d7556044adbeb6d7856cd344ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f867b7350d44cbebe3b10b8685c1336":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28b419031fe84873bd7d0e550ea267d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec958ccc1d1e4703a3c64d06d6be874b","IPY_MODEL_96998c70f8f4452a8d3904689f3e1cb0","IPY_MODEL_703fd91a7dd3446b9b835a3f29078089"],"layout":"IPY_MODEL_08d177e9d0ec4d75b057143f83046a39"}},"ec958ccc1d1e4703a3c64d06d6be874b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14322ad0121d4fe2a476d03492cfa657","placeholder":"​","style":"IPY_MODEL_0e929cb8785e46788919cb8b92649e3e","value":"Downloading flax_model.msgpack: 100%"}},"96998c70f8f4452a8d3904689f3e1cb0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5aa58610341a47ab9950d213f0d4dfa5","max":557690804,"min":0,"orientation":"horizontal","style":"IPY_MODEL_355544ba6eae42569cb546d765021465","value":557690804}},"703fd91a7dd3446b9b835a3f29078089":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e671882b7ff42a3a9fb62719883b0bc","placeholder":"​","style":"IPY_MODEL_eab02bcf35a84b5fbf9bca131a3d2b99","value":" 558M/558M [00:09&lt;00:00, 59.5MB/s]"}},"08d177e9d0ec4d75b057143f83046a39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14322ad0121d4fe2a476d03492cfa657":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e929cb8785e46788919cb8b92649e3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5aa58610341a47ab9950d213f0d4dfa5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"355544ba6eae42569cb546d765021465":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e671882b7ff42a3a9fb62719883b0bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eab02bcf35a84b5fbf9bca131a3d2b99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":112,"metadata":{"id":"vfgjgB1X1Mt2","executionInfo":{"status":"ok","timestamp":1688196105564,"user_tz":-120,"elapsed":9697,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"78aff2de-8d0c-43a4-d9df-07b7a51da189"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["#!pip install sentence-transformers\n","# !apt install libomp-dev\n","# !pip install faiss\n","!pip install torch"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7AI6c81S2waI","executionInfo":{"status":"ok","timestamp":1688191839935,"user_tz":-120,"elapsed":10107,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"f9ff104a-5026-46e8-9383-09a85239c77a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sentence_transformers import SentenceTransformer\n","import numpy as np"],"metadata":{"id":"a0jxFgvS3mVn","executionInfo":{"status":"ok","timestamp":1688193101787,"user_tz":-120,"elapsed":290,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/Colab Notebooks/ds_projects/articles.csv\""],"metadata":{"id":"ggWoIAkd3y3b","executionInfo":{"status":"ok","timestamp":1688191840323,"user_tz":-120,"elapsed":4,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["articles = pd.read_csv(path)"],"metadata":{"id":"agZww2pE3qNW","executionInfo":{"status":"ok","timestamp":1688191841213,"user_tz":-120,"elapsed":893,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["articles.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156},"id":"i8y9xciN3xC-","executionInfo":{"status":"ok","timestamp":1688191841214,"user_tz":-120,"elapsed":15,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"04f73243-0046-41f9-fa3c-b1bd6ae63568"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        author claps  reading_time  \\\n","0   Justin Lee  8.3K            11   \n","1  Conor Dewey  1.4K             7   \n","\n","                                                link  \\\n","0  https://medium.com/swlh/chatbots-were-the-next...   \n","1  https://towardsdatascience.com/python-for-data...   \n","\n","                                               title  \\\n","0  Chatbots were the next big thing: what happene...   \n","1  Python for Data Science: 8 Concepts You May Ha...   \n","\n","                                                text  \n","0  Oh, how the headlines blared:\\nChatbots were T...  \n","1  If you’ve ever found yourself looking up the s...  "],"text/html":["\n","  <div id=\"df-1e59a750-688a-4c2b-b937-86f22d3e8e0b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author</th>\n","      <th>claps</th>\n","      <th>reading_time</th>\n","      <th>link</th>\n","      <th>title</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Justin Lee</td>\n","      <td>8.3K</td>\n","      <td>11</td>\n","      <td>https://medium.com/swlh/chatbots-were-the-next...</td>\n","      <td>Chatbots were the next big thing: what happene...</td>\n","      <td>Oh, how the headlines blared:\\nChatbots were T...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Conor Dewey</td>\n","      <td>1.4K</td>\n","      <td>7</td>\n","      <td>https://towardsdatascience.com/python-for-data...</td>\n","      <td>Python for Data Science: 8 Concepts You May Ha...</td>\n","      <td>If you’ve ever found yourself looking up the s...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e59a750-688a-4c2b-b937-86f22d3e8e0b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1e59a750-688a-4c2b-b937-86f22d3e8e0b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1e59a750-688a-4c2b-b937-86f22d3e8e0b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["articles.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QQ5AzNmO37wG","executionInfo":{"status":"ok","timestamp":1688191841215,"user_tz":-120,"elapsed":12,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"9a4cb745-1dea-4c02-a63d-04f0fd5cd14f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 337 entries, 0 to 336\n","Data columns (total 6 columns):\n"," #   Column        Non-Null Count  Dtype \n","---  ------        --------------  ----- \n"," 0   author        337 non-null    object\n"," 1   claps         337 non-null    object\n"," 2   reading_time  337 non-null    int64 \n"," 3   link          337 non-null    object\n"," 4   title         337 non-null    object\n"," 5   text          337 non-null    object\n","dtypes: int64(1), object(5)\n","memory usage: 15.9+ KB\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xHMcJftF3-au"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Embedding Model Initialization"],"metadata":{"id":"UUMlrFT2GJx6"}},{"cell_type":"code","source":["embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"],"metadata":{"id":"N5zFJWhDGMl4","executionInfo":{"status":"ok","timestamp":1688196541313,"user_tz":-120,"elapsed":1485,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}}},"execution_count":123,"outputs":[]},{"cell_type":"code","source":["sentence = ['This is related to sports', 'that is nice kick with the ball', 'i like the movie john wick super action',\n","            'i love to take wicket with swing ball']\n","test_sentence = [\"I want to watch movie\"]\n","embedding = model.encode(sentence)\n","query_embedding = model.encode(test_sentence)"],"metadata":{"id":"KELQG9SfGNNf","executionInfo":{"status":"ok","timestamp":1688193348001,"user_tz":-120,"elapsed":245,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["embedding.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9pJth5I7GSli","executionInfo":{"status":"ok","timestamp":1688193348388,"user_tz":-120,"elapsed":2,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"b3e0d3a6-3599-4ff7-b0ae-6d3c3edfc94d"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4, 384)"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["query_embedding.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jmT2iCKJGTjN","executionInfo":{"status":"ok","timestamp":1688193348710,"user_tz":-120,"elapsed":4,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"7b1cce54-d441-4f20-a6c3-6369a722f4eb"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 384)"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["# similarity_scores = np.dot(query_embedding[0], embedding.T)\n","# indices = similarity_scores.argsort()[::-1]"],"metadata":{"id":"5V5O6bNyJifT","executionInfo":{"status":"ok","timestamp":1688193410620,"user_tz":-120,"elapsed":242,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["# Index Documents"],"metadata":{"id":"P_-54dELMx0b"}},{"cell_type":"code","source":["sentences = []\n","\n","for index, row in articles.iterrows():\n","  sentences.append(row[\"text\"])\n","\n","indexed_embeddings = model.encode(sentences)"],"metadata":{"id":"B-1bbtGaK0k-","executionInfo":{"status":"ok","timestamp":1688193823662,"user_tz":-120,"elapsed":24452,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}}},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":["# Document Retriever"],"metadata":{"id":"YgOCVjWFM2Lw"}},{"cell_type":"code","source":["def get_top_k_text(df, top_k, query):\n","  query_embedding = embedding_model.encode([query])\n","  similarity_scores = np.dot(query_embedding[0], indexed_embeddings.T)\n","  indices = similarity_scores.argsort()[::-1]\n","  top_indices = indices[0:top_k]\n","  return [articles.iloc[index][\"text\"] for index in top_indices], [articles.iloc[index][\"title\"] for index in top_indices]"],"metadata":{"id":"QWg6FRYOMw01","executionInfo":{"status":"ok","timestamp":1688196545851,"user_tz":-120,"elapsed":237,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}}},"execution_count":124,"outputs":[]},{"cell_type":"code","source":["articles.head(10)[\"title\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mk-N_jCbMfNV","executionInfo":{"status":"ok","timestamp":1688196549050,"user_tz":-120,"elapsed":261,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"20dca5a7-6b26-4517-e2e7-ad662a06fa55"},"execution_count":125,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    Chatbots were the next big thing: what happene...\n","1    Python for Data Science: 8 Concepts You May Ha...\n","2    Automated Feature Engineering in Python – Towa...\n","3    Machine Learning: how to go from Zero to Hero ...\n","4    Reinforcement Learning from scratch – Insight ...\n","5    Intuitively Understanding Convolutions for Dee...\n","6    An intro to Machine Learning for designers – U...\n","7    The Big List of DS/ML Interview Resources – To...\n","8    Must know Information Theory concepts in Deep ...\n","9    What I learned from interviewing at multiple A...\n","Name: title, dtype: object"]},"metadata":{},"execution_count":125}]},{"cell_type":"markdown","source":["# Example Usage of Retriever"],"metadata":{"id":"qQcn6vKXNO2X"}},{"cell_type":"code","source":["query = \"what are the next big things in the world now\"\n","response_text, response_title = get_top_k_text(articles, 5, query)"],"metadata":{"id":"kMy6NQyBLcxz","executionInfo":{"status":"ok","timestamp":1688193984260,"user_tz":-120,"elapsed":247,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["response_title"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5p3J-HdpMoLe","executionInfo":{"status":"ok","timestamp":1688193990107,"user_tz":-120,"elapsed":225,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"569e3480-95f8-4212-b391-0fe687d5ac90"},"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['建议的程序员学习LDA算法的步骤 – 蒸汽与魔法',\n"," 'Eleven Reasons To Be Excited About The Future of Technology',\n"," 'The future of work – Oxford University – Medium',\n"," 'Using Artificial Intelligence to Balance Out Customer Value',\n"," 'Who Is Going To Make Money In AI? Part I – Towards Data Science']"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["query = \"what are chatbots\"\n","response_text, response_title = get_top_k_text(articles, 5, query)"],"metadata":{"id":"d0-BynoRM_ui","executionInfo":{"status":"ok","timestamp":1688194020542,"user_tz":-120,"elapsed":313,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["response_title"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hcfssyjXNHI1","executionInfo":{"status":"ok","timestamp":1688194023108,"user_tz":-120,"elapsed":307,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"aba68ea8-ca45-4595-de0c-c881707802bd"},"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['The Complete Beginner’s Guide To Chatbots – Chatbots Magazine',\n"," 'Chatbots were the next big thing: what happened? – The Startup – Medium',\n"," 'Chatbots were the next big thing: what happened? – The Startup – Medium',\n"," 'Chatbots were the next big thing: what happened? – The Startup – Medium',\n"," 'What Are The Best Intelligent Chatbots or AI Chatbots Available Online?']"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["response_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qTAcELQFNHwR","executionInfo":{"status":"ok","timestamp":1688195691172,"user_tz":-120,"elapsed":506,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"1b6249b4-84be-425d-96f3-d69033d1d670"},"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['What are chatbots? Why are they such a big opportunity? How do they work? How can I build one? How can I meet other people interested in chatbots?\\nThese are the questions we’re going to answer for you right now.\\nReady? Let’s do this.\\n(Do you work in ecommerce? Stop reading and click here, we made something for you.)\\n(p.s. here is where I believe the future of bots is headed, you will probably disagree with me at first.)\\n(p.p.s. My newest guide about conversational commerce is up, I think you’ll find it super interesting.)\\nA chatbot is a service, powered by rules and sometimes artificial intelligence, that you interact with via a chat interface. The service could be any number of things, ranging from functional to fun, and it could live in any major chat product (Facebook Messenger, Slack, Telegram, Text Messages, etc.).\\nIf you haven’t wrapped your head around it yet, don’t worry. Here’s an example to help you visualize a chatbot.\\nIf you wanted to buy shoes from Nordstrom online, you would go to their website, look around until you find the shoes you wanted, and then you would purchase them.\\nIf Nordstrom makes a bot, which I’m sure they will, you would simply be able to message Nordstrom on Facebook. It would ask you what you’re looking for and you would simply... tell it.\\nInstead of browsing a website, you will have a conversation with the Nordstrom bot, mirroring the type of experience you would get when you go into the retail store.\\nWatch this video from Facebook’s recent F8 conference (where they make their major announcements). At the 7:30 mark, David Marcus, the Vice President of Messaging Products at Facebook, explains what it looks like to buy shoes in a Facebook Messenger bot.\\nBuying shoes isn’t the only thing chatbots can be used for. Here are a couple of other examples:\\nSee? With bots, the possibilities are endless. You can build anything imaginable, and I encourage you to do just that.\\nBut why make a bot? Sure, it looks cool, it’s using some super advanced technology, but why should someone spend their time and energy on it?\\nIt’s a huge opportunity. HUGE. Scroll down and I’ll explain.\\nYou are probably wondering “Why does anyone care about chatbots? They look like simple text based services... what’s the big deal?”\\nGreat question. I’ll tell you why people care about chatbots.\\nIt’s because for the first time ever people are using messenger apps more than they are using social networks.\\nLet that sink in for a second.\\nPeople are using messenger apps more than they are using social networks.\\nSo, logically, if you want to build a business online, you want to build where the people are. That place is now inside messenger apps.\\nThis is why chatbots are such a big deal. It’s potentially a huge business opportunity for anyone willing to jump headfirst and build something people want.\\nBut, how do these bots work? How do they know how to talk to people and answer questions? Isn’t that artificial intelligence and isn’t that insanely hard to do?\\nYes, you are correct, it is artificial intelligence, but it’s something that you can totally do yourself.\\nLet me explain.\\nThere are two types of chatbots, one functions based on a set of rules, and the other more advanced version uses machine learning.\\nWhat does this mean?\\nChatbot that functions based on rules:\\nChatbot that functions using machine learning:\\nBots are created with a purpose. A store will likely want to create a bot that helps you purchase something, where someone like Comcast might create a bot that can answer customer support questions.\\nYou start to interact with a chatbot by sending it a message. Click here to try sending a message to the CNN chatbot on Facebook.\\nSo, if these bots use artificial intelligence to make them work well... isn’t that really hard to do? Don’t I need to be an expert at artificial intelligence to be able to build something that has artificial intelligence?\\nShort answer? No, you don’t have to be an expert at artificial intelligence to create an awesome chatbot that has artificial intelligence. Just make sure to not over promise on your application’s abilities. If you can’t make the product good with artificial intelligence right now, it might be best to not put it in yet.\\nHowever, over the past decade quite a bit of advancements have been made in the area of artificial intelligence, so much in fact that anyone who knows how to code can incorporate some level of artificial intelligence into their products.\\nHow do you build artificial intelligence into your bot? Don’t worry, I’ve got you covered, I’ll tell you how to do it in the next section of this post.\\nBuilding a chatbot can sound daunting, but it’s totally doable. You’ll be creating an artificial intelligence powered chatting machine in no time (or, of course, you can always build a basic chat bot that doesn’t have a fancy AI brain and strictly follows rules).\\nYou will need to figure out what problem you are going to solve with your bot, choose which platform your bot will live on (Facebook, Slack, etc), set up a server to run your bot from, and choose which service you will use to build your bot.\\nHere are a ton of resources to get you started.\\nPlatform documentation:\\nOther Resources:\\nDon’t want to build your own?\\nNow that you’ve got your chatbot and artificial intelligence resources, maybe it’s time you met other people who are also interested in chatbots.\\nChatbots have been around for decades, but because of the recent advancements in artificial intelligence and machine learning, there is a big opportunity for people to create bots that are better, faster, and stronger.\\nIf you’re reading this, you probably fall into one of these categories:\\nWouldn’t it be awesome if you had a place to meet, learn, and share information with other people interested in chatbots? Yeah, we thought so too.\\nThat’s why I created a forum called “Chatbot News”, and it has quickly become the largest community related to Chatbots.\\nThe members of the Chatbots group are investors who manage well over $2 billion in capital, employees at Facebook, Instagram, Fitbit, Nike, and Ycombinator companies, and hackers from around the world.\\nWe would love if you joined. Click here to request an invite private chatbots community.\\nI have also created the Silicon Valley Chatbots Meetup, register here to be notified when we schedule our first event.\\nFrom a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\\nCEO of Octane AI, Founder of Chatbots Magazine, YC Alum, Forbes 30 Under 30, product at Ustream for 4 years (sold for $130mil), did digital for Lil Wayne.\\nChatbots, AI, NLP, Facebook Messenger, Slack, Telegram, and more.\\n',\n"," \"Oh, how the headlines blared:\\nChatbots were The Next Big Thing.\\nOur hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.\\nAnd why wouldn’t they be? All the road signs pointed towards insane success.\\nAt the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’.\\nIn fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place:\\nOne year on, we have an answer to that question.\\nNo.\\nBecause there isn’t even an ecosystem for a platform to dominate.\\nChatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly.\\nThe age-old hype cycle unfolded in familiar fashion...\\nExpectations built, built, and then..... It all kind of fizzled out.\\nThe predicted paradim shift didn’t materialize.\\nAnd apps are, tellingly, still alive and well.\\nWe look back at our breathless optimism and turn to each other, slightly baffled:\\n“is that it? THAT was the chatbot revolution we were promised?”\\nDigit’s Ethan Bloch sums up the general consensus:\\nAccording to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail: they took on several and failed all of them.\\nBots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word.\\nUsers had to type commands manually into a machine to get anything done.\\nThen, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too!\\nMeanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language.\\nAnother bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised:\\nThe next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system:\\nPretty cool, right? The system takes turns in collaborative way, and does a smart job of figuring out what the user wants.\\nIt was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations.\\nModern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms.\\nBasically, we’re still trying to achieve the same innovations we were 30 years ago.\\nHere’s where I think we’re going wrong:\\nAn oversized assumption has been that apps are ‘over’, and would be replaced by bots.\\nBy pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development.\\nYou might remember a similar war cry when apps first came onto the scene ten years ago: but do you remember when apps replaced the internet?\\nIt’s said that a new product or service needs to be two of the following: better, cheaper, or faster. Are chatbots cheaper or faster than apps? No — not yet, at least.\\nWhether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app.\\nPlus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail.\\nA great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition.\\nThat’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems.\\nModern-day apps benefit from decades of research and experimentation. Why would we throw this away?\\nBut, if we swap the word ‘replace’ with ‘extend’, things get much more interesting.\\nToday’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements.\\nThe next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.\\nAnother problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these.\\nFor plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed.\\nBuilding a bot for the sake of it, letting it loose and hoping for the best will never end well:\\nThe vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.\\nThe advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too.\\nThat’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate.\\nProblems arise when life refuses to fit into those boxes.\\nAccording to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus.\\nWhen we were building GrowthBot, we decided to make it specific to sales and marketers: not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties.\\nRemember: a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly.\\nA competent developer can build a basic bot in minutes — but one that can hold a conversation? That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like.\\nIn an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy.\\nSome platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.)\\nAs Matt Asay outlines, this results in another issue: failure to capture the attention and creativity of developers.\\nAnd conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish.\\nToday’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet.\\nAnd in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked:\\nOnce upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate information\\nThere’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type.\\nTapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true.\\nWe love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication.\\nConversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative.\\nSure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.\\nAiming for a human dimension in business interactions makes sense.\\nIf there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.\\nFacebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.\\nA conversation encompasses so much more than just text.\\nHumans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.\\nAs HubSpot team pinpointed:\\nPeople aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).\\nAnd even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.\\nAnd here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.\\nBut is that how humans prefer to interact with machines?\\nNot necessarily.\\nAt the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.\\nIn a way, those early-adopters weren’t entirely wrong.\\nPeople are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.\\nNot even close.\\nComputers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information.\\nComputers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel.\\nThat’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch: empathy and emotional intelligence.\\nFor now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon.\\nBut that’s not the whole story.\\nYes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial.\\nAs Bill Gates once said:\\nThe hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone.\\nI believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology.\\nMessaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day.\\nDevelopers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing.\\nAnd I can’t wait to see what happens next.\\nFrom a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\\nHead of Growth for GrowthBot, Messaging & Conversational Strategy @HubSpot\\nMedium's largest publication for makers. Subscribe to receive our top stories here → https://goo.gl/zHcLJi\\n\",\n"," \"Oh, how the headlines blared:\\nChatbots were The Next Big Thing.\\nOur hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.\\nAnd why wouldn’t they be? All the road signs pointed towards insane success.\\nAt the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’.\\nIn fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place:\\nOne year on, we have an answer to that question.\\nNo.\\nBecause there isn’t even an ecosystem for a platform to dominate.\\nChatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly.\\nThe age-old hype cycle unfolded in familiar fashion...\\nExpectations built, built, and then..... It all kind of fizzled out.\\nThe predicted paradim shift didn’t materialize.\\nAnd apps are, tellingly, still alive and well.\\nWe look back at our breathless optimism and turn to each other, slightly baffled:\\n“is that it? THAT was the chatbot revolution we were promised?”\\nDigit’s Ethan Bloch sums up the general consensus:\\nAccording to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail: they took on several and failed all of them.\\nBots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word.\\nUsers had to type commands manually into a machine to get anything done.\\nThen, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too!\\nMeanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language.\\nAnother bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised:\\nThe next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system:\\nPretty cool, right? The system takes turns in collaborative way, and does a smart job of figuring out what the user wants.\\nIt was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations.\\nModern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms.\\nBasically, we’re still trying to achieve the same innovations we were 30 years ago.\\nHere’s where I think we’re going wrong:\\nAn oversized assumption has been that apps are ‘over’, and would be replaced by bots.\\nBy pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development.\\nYou might remember a similar war cry when apps first came onto the scene ten years ago: but do you remember when apps replaced the internet?\\nIt’s said that a new product or service needs to be two of the following: better, cheaper, or faster. Are chatbots cheaper or faster than apps? No — not yet, at least.\\nWhether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app.\\nPlus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail.\\nA great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition.\\nThat’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems.\\nModern-day apps benefit from decades of research and experimentation. Why would we throw this away?\\nBut, if we swap the word ‘replace’ with ‘extend’, things get much more interesting.\\nToday’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements.\\nThe next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.\\nAnother problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these.\\nFor plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed.\\nBuilding a bot for the sake of it, letting it loose and hoping for the best will never end well:\\nThe vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.\\nThe advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too.\\nThat’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate.\\nProblems arise when life refuses to fit into those boxes.\\nAccording to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus.\\nWhen we were building GrowthBot, we decided to make it specific to sales and marketers: not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties.\\nRemember: a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly.\\nA competent developer can build a basic bot in minutes — but one that can hold a conversation? That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like.\\nIn an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy.\\nSome platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.)\\nAs Matt Asay outlines, this results in another issue: failure to capture the attention and creativity of developers.\\nAnd conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish.\\nToday’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet.\\nAnd in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked:\\nOnce upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate information\\nThere’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type.\\nTapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true.\\nWe love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication.\\nConversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative.\\nSure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.\\nAiming for a human dimension in business interactions makes sense.\\nIf there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.\\nFacebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.\\nA conversation encompasses so much more than just text.\\nHumans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.\\nAs HubSpot team pinpointed:\\nPeople aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).\\nAnd even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.\\nAnd here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.\\nBut is that how humans prefer to interact with machines?\\nNot necessarily.\\nAt the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.\\nIn a way, those early-adopters weren’t entirely wrong.\\nPeople are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.\\nNot even close.\\nComputers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information.\\nComputers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel.\\nThat’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch: empathy and emotional intelligence.\\nFor now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon.\\nBut that’s not the whole story.\\nYes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial.\\nAs Bill Gates once said:\\nThe hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone.\\nI believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology.\\nMessaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day.\\nDevelopers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing.\\nAnd I can’t wait to see what happens next.\\nFrom a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\\nHead of Growth for GrowthBot, Messaging & Conversational Strategy @HubSpot\\nMedium's largest publication for makers. Subscribe to receive our top stories here → https://goo.gl/zHcLJi\\n\",\n"," \"Oh, how the headlines blared:\\nChatbots were The Next Big Thing.\\nOur hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.\\nAnd why wouldn’t they be? All the road signs pointed towards insane success.\\nAt the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’.\\nIn fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place:\\nOne year on, we have an answer to that question.\\nNo.\\nBecause there isn’t even an ecosystem for a platform to dominate.\\nChatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly.\\nThe age-old hype cycle unfolded in familiar fashion...\\nExpectations built, built, and then..... It all kind of fizzled out.\\nThe predicted paradim shift didn’t materialize.\\nAnd apps are, tellingly, still alive and well.\\nWe look back at our breathless optimism and turn to each other, slightly baffled:\\n“is that it? THAT was the chatbot revolution we were promised?”\\nDigit’s Ethan Bloch sums up the general consensus:\\nAccording to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail: they took on several and failed all of them.\\nBots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word.\\nUsers had to type commands manually into a machine to get anything done.\\nThen, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too!\\nMeanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language.\\nAnother bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised:\\nThe next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system:\\nPretty cool, right? The system takes turns in collaborative way, and does a smart job of figuring out what the user wants.\\nIt was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations.\\nModern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms.\\nBasically, we’re still trying to achieve the same innovations we were 30 years ago.\\nHere’s where I think we’re going wrong:\\nAn oversized assumption has been that apps are ‘over’, and would be replaced by bots.\\nBy pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development.\\nYou might remember a similar war cry when apps first came onto the scene ten years ago: but do you remember when apps replaced the internet?\\nIt’s said that a new product or service needs to be two of the following: better, cheaper, or faster. Are chatbots cheaper or faster than apps? No — not yet, at least.\\nWhether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app.\\nPlus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail.\\nA great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition.\\nThat’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems.\\nModern-day apps benefit from decades of research and experimentation. Why would we throw this away?\\nBut, if we swap the word ‘replace’ with ‘extend’, things get much more interesting.\\nToday’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements.\\nThe next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.\\nAnother problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these.\\nFor plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed.\\nBuilding a bot for the sake of it, letting it loose and hoping for the best will never end well:\\nThe vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.\\nThe advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too.\\nThat’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate.\\nProblems arise when life refuses to fit into those boxes.\\nAccording to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus.\\nWhen we were building GrowthBot, we decided to make it specific to sales and marketers: not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties.\\nRemember: a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly.\\nA competent developer can build a basic bot in minutes — but one that can hold a conversation? That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like.\\nIn an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy.\\nSome platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.)\\nAs Matt Asay outlines, this results in another issue: failure to capture the attention and creativity of developers.\\nAnd conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish.\\nToday’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet.\\nAnd in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked:\\nOnce upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate information\\nThere’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type.\\nTapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true.\\nWe love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication.\\nConversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative.\\nSure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.\\nAiming for a human dimension in business interactions makes sense.\\nIf there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.\\nFacebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.\\nA conversation encompasses so much more than just text.\\nHumans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.\\nAs HubSpot team pinpointed:\\nPeople aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).\\nAnd even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.\\nAnd here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.\\nBut is that how humans prefer to interact with machines?\\nNot necessarily.\\nAt the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.\\nIn a way, those early-adopters weren’t entirely wrong.\\nPeople are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.\\nNot even close.\\nComputers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information.\\nComputers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel.\\nThat’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch: empathy and emotional intelligence.\\nFor now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon.\\nBut that’s not the whole story.\\nYes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial.\\nAs Bill Gates once said:\\nThe hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone.\\nI believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology.\\nMessaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day.\\nDevelopers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing.\\nAnd I can’t wait to see what happens next.\\nFrom a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\\nHead of Growth for GrowthBot, Messaging & Conversational Strategy @HubSpot\\nMedium's largest publication for makers. Subscribe to receive our top stories here → https://goo.gl/zHcLJi\\n\",\n"," 'How do we define the intelligence of a chatbot? You can see a lot of articles about what would make a chatbot “appear intelligent.” A chatbot is intelligent when it becomes aware of user needs. Its intelligence is what gives the chatbot the ability to handle any scenario of a conversation with ease.\\nAre the travel bots or the weather bots that have buttons that you click and give you some query, artificially intelligent? Definitely, but they are just not far along the conversation axis. It can be a wonderfully designed conversational interface that is smooth and easy to use. It could be natural language processing and understanding where it is able to understand sentences that you structure in the wrong way. Now, it is easier than ever to make a bot from scratch. Also chatbot development platforms like Chatfuel, Gupshup make it fairly simple to build a chatbot without a technical background. Hence, making the reach for chatbot easy and transparent to anyone who would like to have one for their business. For more understanding on intelligent chatbots, read our blog.\\nThe best AI based chatbots available online are Mitsuku, Rose, Poncho, Right Click, Insomno Bot, Dr. AI and Melody.\\nThis chatbot is one the best AI chatbots and it’s my favorite too. Evidently it is the current winner of Loebner Prize. The Loebner Prize is an annual competition in artificial intelligence that awards prizes to the chatterbot considered by the judges to be the most human-like. The format of the competition is that of a standard Turing test. You can talk with Mitsuku for hours without getting bored. It replies to your question in the most humane way and understands your mood with the language you’re using.\\nIt is a bot made to chat about anything, which is one of the main reasons that make it so human-like — contrary to other chatbots that are made for a specific task.\\nRose is a chatbot, and a very good one — she won recognition this past Saturday as the most human-like chatbot in a competition described as the first Turing test, the Loebner Prize in 2014 and 2015.\\nRight Click is a startup that introduced an A.I.-powered chatbot that creates websites. It asks general questions during the conversation like “What industry you belong to?” and “Why do you want to make a website?” and creates customized templates as per the given answers. Hira Saeed tried to divert it from its job by asking it about love, but what a smart player it is! By replying to each of her queries, it tried to bring her back to the actual job of website creation. The process was short but keeps you hooked.\\nPoncho is a Messenger bot designed to be your one and only weather expert. It sends alerts up to twice a day with user consent and is intelligent enough to answer questions like “Should I take an umbrella today?”\\nRead Poncho developer’s piece: Think Differently When Building Bots\\nInsomno bot is for night owls. As the name suggests, it is for all people out there who have trouble sleeping. This bot talks to you when you have no one around and gives you amazing replies so that you won’t get bored. It’s not something that will help you count stars when you can’t sleep or help you with reading suggestions, but this bot talks to you about anything.\\nIt asks about symptoms, body parameters and medical history, then compiles a list of the most and least likely causes for the symptoms and ranks them by order of seriousness.\\nIt lives inside the existing Biadu Doctor app. This app collects medical information from people and then passes it to doctors in a form that makes it easier to use for diagnostic purposes or to otherwise respond to.\\nFeatured CBM: The Future, Healthcare, and Conversational UI\\nThese are just the basic versions of intelligent chatbots. There are many more intelligent chatbots out there which provide a much more smarter approach to responding to queries. Since the process of making a intelligent chatbot is not a big task, most of us can achieve it with the most basic technical knowledge. Many of which will be very extremely helpful in the service industry and also help provide a better customer experience.\\nThe most important part of any chatbot is the conversation it has with its user. Hence, more effort has to be put in designing a chatbot conversation. Hope you had a good read. To know more about Chatbots and how they converse with people, visit the link below.\\nFeatured CBM: How to Make a Chatbot Intelligent?\\nIf you resonated with this article, please subscribe to our newsletter. You will get a free copy of our Case Study on Business Automation through our Bot solution.\\nFrom a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\\nProfessional team delivering enterprise software solutions — Bot development, Big Data Analytics, Web & Mobile Apps, and AI & ML integration.\\nChatbots, AI, NLP, Facebook Messenger, Slack, Telegram, and more.\\n']"]},"metadata":{},"execution_count":88}]},{"cell_type":"markdown","source":["# Question Answer LLM"],"metadata":{"id":"xbjz31PhNTo6"}},{"cell_type":"code","source":["from transformers import BartTokenizer, BartForConditionalGeneration\n","from transformers import FlaxBartForQuestionAnswering"],"metadata":{"id":"MaMCHUqBNWLt","executionInfo":{"status":"ok","timestamp":1688195060528,"user_tz":-120,"elapsed":882,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["8cc4cb90c6a1451d8b515e7eaa9cedee","12c3ef3cc9594364b4999d77dd0a48f0","97d2efecfbad43fd9648fe03eb916e2f","9ccaa246e52740dabeacb0f92ce38f04","7fb7ed782dd54ce6b33774b63d7e4ff9","35d9715908234e5bb6af7677b0f77b8a","1c28f36a19a44617bf1b8ea51d458572","43be36c363e446edbf92e34d7baa3c3c","a99fa814f18046e280535626444861b3","9dbd74b6742243d188a45aa28a9ea7c6","2a9d4540b3b44539a136bdc85dadc489","d8a7d2c5ea564035a1d1b61dd7dde4b9","2a2671ef993a4bdebe6ef1580d57241f","59a2326cefd04cd6890aa3b12e2dd881","5af5c702276d4837b77df32c033bf81d","c614c569d9004dcb9b67d2b7930cdb3f","b7094ffd221b4437812beae06f6c9411","6167ee562f3c429eaeb2d081e91790f2","8035d09d90e14f78a180c218885d2d2d","9b1284a8ffd84b7c830fd11494b12078","58b2c0f7e38a4671b7cf67f70ebee13c","4d22fca97607402197ce7003fd1e1554","a3c4a5d00e044f0180ac77068e6fde26","880a1b7a165a4a7a974122e3d454b7bc","fa451a0a7fc240c3a026c99f5a330457","67e9d3f973fa4a699a5940864570de67","4c99045f018847d68dbdaba0224bda91","20cbd9d6be884881a190b1b682a87d82","e4bb7844942d4a80887580a7cd99385e","f00c2b56f56243ac89f2252615325c6a","5b2eace6ef424515aa1015622a690c7c","66257dd2a8314a939f0b44d177a847f4","6dcc248bdc794836968702cf45e04698"]},"id":"q5TG1eRzN8te","executionInfo":{"status":"ok","timestamp":1688194829606,"user_tz":-120,"elapsed":1509,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"694827f2-b6c8-4835-a71d-f222cee9018e"},"execution_count":68,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cc4cb90c6a1451d8b515e7eaa9cedee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8a7d2c5ea564035a1d1b61dd7dde4b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3c4a5d00e044f0180ac77068e6fde26"}},"metadata":{}}]},{"cell_type":"code","source":["model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\", forced_bos_token_id=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["f00a41a6fe3c4f3ba7fa90dd861b47dc","48f14c70a53149b4abcc93f50ad2403f","be9c2fecb2e14e8895898a05d01600a6","9aa61c4034354207b69b71f430c5c3cd","c44ece6052e047468f06181b57a81385","9cbd8adb16484d09b434614551156c19","7b118a8fea47460da65051024a73bd52","6cab9f6aa59e44818cadfb3d0a8e8bf0","5950cffa4f014d4fb7c4eda8c804207d","5e6ff2d7556044adbeb6d7856cd344ac","0f867b7350d44cbebe3b10b8685c1336"]},"id":"vx-Np6wKOUHu","executionInfo":{"status":"ok","timestamp":1688194921917,"user_tz":-120,"elapsed":21190,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"65fe64b7-819a-4974-b5c0-717655cd956c"},"execution_count":69,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f00a41a6fe3c4f3ba7fa90dd861b47dc"}},"metadata":{}}]},{"cell_type":"code","source":["qa_model = FlaxBartForQuestionAnswering.from_pretrained(\"facebook/bart-base\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":123,"referenced_widgets":["28b419031fe84873bd7d0e550ea267d8","ec958ccc1d1e4703a3c64d06d6be874b","96998c70f8f4452a8d3904689f3e1cb0","703fd91a7dd3446b9b835a3f29078089","08d177e9d0ec4d75b057143f83046a39","14322ad0121d4fe2a476d03492cfa657","0e929cb8785e46788919cb8b92649e3e","5aa58610341a47ab9950d213f0d4dfa5","355544ba6eae42569cb546d765021465","0e671882b7ff42a3a9fb62719883b0bc","eab02bcf35a84b5fbf9bca131a3d2b99"]},"id":"Zo1-tswaQeF9","executionInfo":{"status":"ok","timestamp":1688195199929,"user_tz":-120,"elapsed":33785,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"04c5e300-1b16-47f1-ec66-03a4e2a61d81"},"execution_count":72,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading flax_model.msgpack:   0%|          | 0.00/558M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28b419031fe84873bd7d0e550ea267d8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n","Some weights of FlaxBartForQuestionAnswering were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: {('qa_outputs', 'bias'), ('qa_outputs', 'kernel')}\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n","\n","text = \"Essentially, we’re swapping something simple for a more-complex alternative.\\nSure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.\\nAiming for a human dimension in business interactions makes sense.\\nIf there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.\\nFacebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.\\nA conversation encompasses so much more than just text.\\nHumans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.\\nAs HubSpot team pinpointed:\\nPeople aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).\\nAnd even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.\\nAnd here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.\\nBut is that how humans prefer to interact with machines?\\nNot necessarily.\\nAt the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.\\nIn a way, those early-adopters weren’t entirely wrong.\\nPeople are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.\\nNot even close.\\nComputers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information\"\n","question = \"what is broken about sales and marketing\""],"metadata":{"id":"TcqhqXXgRaMy","executionInfo":{"status":"ok","timestamp":1688195745848,"user_tz":-120,"elapsed":272,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["inputs = tokenizer(question, text, return_tensors=\"jax\")"],"metadata":{"id":"m11Wq6pPRqKi","executionInfo":{"status":"ok","timestamp":1688195747157,"user_tz":-120,"elapsed":268,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["#inputs"],"metadata":{"id":"_R12GbCuRsPt","executionInfo":{"status":"ok","timestamp":1688196203021,"user_tz":-120,"elapsed":241,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}}},"execution_count":117,"outputs":[]},{"cell_type":"code","source":["outputs = qa_model(**inputs)"],"metadata":{"id":"26Bcf_teRtB_","executionInfo":{"status":"ok","timestamp":1688195904750,"user_tz":-120,"elapsed":5824,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}}},"execution_count":102,"outputs":[]},{"cell_type":"code","source":["outputs[\"output_logits\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XX8CWFwsRyQa","executionInfo":{"status":"ok","timestamp":1688195760526,"user_tz":-120,"elapsed":25,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"b8647fd3-da42-4beb-8b62-ef6eb3a950f0"},"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FlaxSeq2SeqQuestionAnsweringModelOutput(start_logits=Array([[ 0.12429245,  0.6879718 ,  0.9607391 ,  0.38230354, -0.78611434,\n","        -0.00594745,  0.0814611 ,  1.53239   , -0.0848643 ,  0.11409563,\n","         0.10934819, -0.18166989, -0.90862495, -0.6875577 ,  0.35753164,\n","         0.7494087 , -0.9083259 ,  0.4646651 , -0.89260197, -0.69570965,\n","        -0.91500306,  0.4545213 ,  1.2399535 ,  0.2987823 ,  0.16216023,\n","        -0.38533884, -1.6747088 , -0.95684725, -0.6829569 , -0.6108008 ,\n","        -0.47563598,  0.67845863, -0.47935197, -1.0877166 , -0.5026999 ,\n","        -0.14632261,  1.8426483 ,  0.85395294,  1.1931043 , -0.8417158 ,\n","        -0.05845101, -1.3279247 , -0.45386702,  0.29421744,  0.40680638,\n","         0.671847  ,  0.16606909, -0.00363436,  0.6094322 , -1.1942548 ,\n","         0.1466212 ,  0.88439363,  0.3453309 ,  0.09063312, -1.323919  ,\n","         1.8873427 , -0.39013198,  1.2988083 , -0.48016122, -0.6339157 ,\n","        -0.13209447,  1.2536767 ,  1.237092  ,  1.115227  ,  1.3420014 ,\n","         0.4175626 , -0.8384071 ,  1.7967988 ,  0.49843353, -0.5704187 ,\n","         1.2305013 , -0.36619562, -0.9251834 , -0.540066  , -0.56446904,\n","         1.0066094 ,  0.66405123,  1.163955  , -0.52578056,  0.0525102 ,\n","         1.0840619 , -0.8105569 , -0.14094818, -0.6395738 ,  0.03501123,\n","        -0.90125513, -0.19684055, -1.5884216 ,  0.90727043,  0.95259756,\n","         0.02699111, -0.9118401 ,  0.11621088, -1.1187047 ,  0.19538605,\n","        -0.19431147, -0.01790842,  0.13985518,  0.4927481 ,  0.28282994,\n","        -0.31303853,  0.6049396 ,  0.42093417, -0.1526792 , -0.5423738 ,\n","         0.30664253, -1.4394374 ,  0.21224673,  0.0361525 ,  0.16009226,\n","         0.95112514,  0.57785165, -0.80462945, -0.19803226, -0.6314215 ,\n","        -0.17129958,  0.33788252,  0.6896281 , -0.96716774,  0.68717635,\n","        -0.82846344, -0.06665276, -0.2136909 ,  1.5842304 , -1.0124179 ,\n","        -0.03976788,  0.9193063 ,  0.61459816, -0.9015402 ,  0.17566547,\n","        -0.94482005, -0.6812457 ,  0.16980457, -0.6230571 ,  0.13700756,\n","         0.7265266 , -2.6912165 ,  0.40169537, -0.9992433 , -0.8350706 ,\n","         0.3605426 , -0.5489452 , -1.2381566 ,  0.03194129, -0.26539958,\n","        -0.37382334,  0.20942071,  0.50555986,  0.23776363,  0.4799591 ,\n","        -0.18989813, -0.32217717, -0.42562902, -0.84040284,  0.19805957,\n","         1.1633986 ,  0.5149027 ,  0.0932644 ,  0.63263947,  0.14297944,\n","        -0.8539178 , -0.21172136,  1.381355  , -0.66898835, -1.6379678 ,\n","         0.32219917,  0.02388122,  0.10018946,  0.00484174, -0.55696344,\n","         0.5297997 , -0.2546125 ,  0.21651934,  0.9975792 , -1.0011237 ,\n","         0.06842142, -0.49939272, -0.51886284, -0.03931758, -1.0970091 ,\n","        -1.4797127 , -1.5201263 , -1.2910728 , -2.1042376 , -0.6588737 ,\n","        -1.6577268 ,  2.5743473 ,  0.8085873 ,  0.82326704,  0.384178  ,\n","         0.9158872 , -0.6432104 , -0.4969384 ,  1.0128121 ,  0.00881487,\n","         0.6003833 ,  1.0090637 , -0.460406  , -1.2468287 ,  1.0911157 ,\n","        -0.09306276, -1.7659034 , -1.5155547 ,  0.3723318 ,  0.07908273,\n","        -1.0918832 , -0.05190873,  0.8385314 , -0.25887707, -0.30901453,\n","        -1.4652438 , -1.7056367 ,  0.42999402,  0.83658314, -0.83197594,\n","        -0.33503318,  0.93201745,  0.19620182, -1.071164  , -1.5288173 ,\n","         0.4090646 ,  0.14970136,  0.6748917 , -0.1175279 ,  0.2530136 ,\n","         1.2065866 ,  0.723021  , -0.18094796,  1.2515904 , -0.62810904,\n","        -1.6626196 , -0.07901596, -0.14636813, -0.08754525,  1.1408694 ,\n","         0.47874254, -1.0702095 , -0.15914375,  0.54319715, -0.9195089 ,\n","         1.0542161 , -0.8328024 , -2.3004475 , -0.3449971 ,  1.749471  ,\n","         0.5292373 , -0.78771704, -1.4491857 , -0.46079037, -0.31103176,\n","        -1.5191423 , -1.0526073 ,  0.94280666,  0.75136316, -1.2041332 ,\n","         0.5620518 ,  0.7045841 ,  0.6593163 , -0.4617743 , -0.45073146,\n","        -0.88140225, -1.0987364 ,  0.05843997,  0.9638752 ,  2.271759  ,\n","         0.47643298,  0.20266971,  0.5747909 ,  0.64268386, -1.2237244 ,\n","        -1.4575676 , -0.62524956,  0.2334018 , -0.01869261,  0.97958434,\n","         1.2029002 ,  2.0836747 , -0.5596733 ,  1.1563275 , -0.51959187,\n","        -0.60718215, -0.07839879,  0.7289655 , -1.3578533 ,  0.5003357 ,\n","         0.29279155, -0.47489876, -0.48208398, -0.8343581 ,  0.13724545,\n","         0.7082504 ,  0.3970045 ,  0.67016745,  0.45586094,  0.06117084,\n","         0.32620513,  0.8293545 , -0.20846461,  0.4045363 ,  0.6608413 ,\n","        -1.3779342 , -0.04252343,  0.44328377,  0.528384  , -0.16012263,\n","        -0.82502496, -0.48222083, -0.03067213,  0.22726877,  0.34338176,\n","         0.9451257 ,  1.620273  , -0.05989701, -0.6082742 , -0.89458627,\n","         0.3014285 ,  0.05448792, -0.08736998, -0.8174727 ,  0.65929997,\n","        -0.07895066,  1.2585586 ,  0.89559186,  0.43564188,  0.0248895 ,\n","         1.0164896 ,  0.68152785,  0.72202927, -0.4212895 ,  0.5405101 ,\n","         0.02028368,  0.3274709 , -0.2444703 , -0.44659498, -2.0871453 ,\n","        -0.83667076,  0.9290483 , -0.07700387, -1.024347  ,  0.10002328,\n","        -0.9668998 , -0.5125448 , -1.710772  , -0.508531  , -1.23053   ,\n","        -0.48969927, -0.21734954, -0.51682127, -0.8296505 ,  0.49739486,\n","         1.7757324 , -0.18362391, -0.06287099, -0.97201157, -0.3809234 ,\n","         0.45072865, -0.1609242 ,  1.0662825 ,  1.9006287 , -0.28190833,\n","         0.7442919 ,  0.04041405, -1.7725905 ,  0.55119324,  0.074276  ,\n","        -0.04132883,  0.47969574,  0.9380543 , -0.59934187,  0.35149428,\n","        -0.82038987, -0.45060217, -0.94852257, -0.40114945, -0.5234778 ,\n","         0.40335244,  0.17387219,  0.28116274, -0.8008493 , -0.1804524 ,\n","         1.4824054 , -0.0930593 ,  1.2269044 , -2.0466971 ,  1.0107493 ,\n","         0.26079255,  0.8613064 , -1.441971  ,  0.13333014, -0.91361195,\n","        -0.5590881 , -1.1608073 ,  0.41446126,  0.0861921 , -0.32385013,\n","        -0.38051507,  0.10180163, -1.1446376 ,  0.94980055,  0.27868164,\n","         0.41720784,  0.23330837, -0.678726  , -0.4767009 ,  0.29797113,\n","        -0.2505586 ,  1.716977  , -0.37071514,  0.40717387,  0.5982303 ,\n","         0.06215812,  1.0869373 , -0.30981642, -0.28543454,  0.3147378 ,\n","        -0.575523  , -0.3197808 , -0.09786427, -0.19117561, -0.61284053,\n","        -0.55924475,  0.19388153,  0.04782802, -0.6621041 , -0.24650277,\n","        -0.5966885 , -0.51955223, -0.514257  ,  0.1268712 ,  0.04838496,\n","         0.00496159,  0.10007083, -0.77266467, -0.95159507, -1.0219643 ,\n","        -0.62238276, -1.0313843 ,  0.19101149,  0.5124954 ,  0.04153615,\n","         0.59151673, -0.4579494 , -0.65684164,  0.4348441 , -0.2815851 ,\n","        -0.07113534,  0.4850311 , -0.48990276, -1.1524645 , -0.9055457 ,\n","         0.5236171 , -0.788408  ,  0.10860202, -0.6966016 , -1.2323589 ,\n","        -0.05978879, -0.0206738 ,  0.60179627, -0.18378955, -0.31585208,\n","        -0.0298795 , -1.235099  , -0.9992081 ,  0.01305494,  0.17301142,\n","         0.05207247, -0.4158077 , -1.2205994 , -0.08360603, -0.51064706,\n","        -1.3487542 , -0.39891025, -0.8861478 , -1.4946847 , -1.3700836 ,\n","        -1.0838838 , -1.9853052 , -1.0648557 , -1.3671949 ,  0.15701616,\n","         0.1386253 , -0.45001954, -1.3013278 , -0.8211758 , -1.0446671 ,\n","         0.97174615, -2.2645535 , -0.942187  , -0.3017822 , -0.75709295,\n","        -1.1806732 ,  0.16421239, -0.44720876, -0.9134463 ,  0.22876729,\n","        -0.20558551, -1.1063378 , -0.21644954,  0.5407876 , -0.4497502 ,\n","        -0.07016605,  0.3568589 , -0.33186793,  0.6481778 , -1.8300588 ,\n","        -0.08468816,  0.03364863, -0.1973685 , -0.6576766 , -0.3470792 ,\n","        -0.21474943, -0.2702242 , -0.69888544, -1.1890895 ,  0.41074038,\n","        -0.03837566,  1.1118237 ,  0.22972476, -0.62808794,  0.19409776,\n","        -0.20237839, -0.23489773,  0.09122811, -0.12205088, -0.33874017,\n","        -0.7421893 , -0.09854275, -0.97961473, -1.0733938 , -0.49463752,\n","         0.18262292,  0.07178263, -0.500028  ,  0.1849803 , -0.20618702,\n","        -0.40433893, -0.6787391 , -0.3100512 , -0.5422509 , -0.32870144,\n","        -0.38828397, -0.52540046, -0.63179624, -0.57994395, -0.13244376]],      dtype=float32), end_logits=Array([[ 1.61773527e+00,  1.12480557e+00,  9.36217546e-01,\n","         9.00279641e-01,  8.01208556e-01,  2.55866617e-01,\n","         8.61955583e-01, -2.21382588e-01,  1.48109481e-01,\n","        -6.42113209e-01, -7.96979129e-01, -2.08820915e+00,\n","        -2.01704621e-01, -4.88460481e-01,  1.23514557e+00,\n","        -3.78393233e-01, -2.86571980e-02,  2.96163321e-01,\n","         1.00568271e+00, -1.74787641e-02,  3.33997309e-01,\n","         1.18345666e+00,  2.48024583e-01,  1.32313073e-01,\n","        -6.37971163e-02,  3.97567511e-01,  8.90042484e-02,\n","        -1.11590958e+00,  2.59716719e-01,  3.65045488e-01,\n","        -4.69356537e-01,  1.49598062e+00,  1.01067495e+00,\n","         9.84893858e-01, -6.75350666e-01,  3.84651780e-01,\n","         1.06606841e+00,  1.08924055e+00, -5.97996235e-01,\n","        -1.41458631e-01, -7.14659929e-01,  8.97094607e-01,\n","         6.17394805e-01, -4.81182963e-01, -4.70594287e-01,\n","        -1.78040743e-01, -5.81562400e-01, -2.18857622e+00,\n","        -2.50146389e-02, -1.36327398e+00, -1.86966968e+00,\n","        -3.16076577e-01, -1.37749195e-01, -2.01435089e-01,\n","        -7.26375341e-01,  7.29209542e-01,  3.14862728e-01,\n","         7.92230189e-01,  6.30016804e-01,  5.48657537e-01,\n","        -1.16181350e+00, -1.91462487e-01, -8.05756569e-01,\n","         1.07299089e-01, -5.35371423e-01, -3.01756740e-01,\n","        -2.64139414e-01,  5.52637100e-01, -1.19742405e+00,\n","         2.24577010e-01, -6.86428487e-01,  7.14724422e-01,\n","         7.03474164e-01,  4.27316427e-01,  9.89055276e-01,\n","         5.93675256e-01,  7.66220033e-01,  1.97526312e+00,\n","         2.58015919e+00, -2.23038197e-02, -1.32335529e-01,\n","         1.02803981e+00,  1.55137300e-01, -2.04581785e+00,\n","        -1.09539247e+00, -2.94716388e-01,  1.24053764e+00,\n","         1.25257671e+00,  3.55526209e-02,  1.02372801e+00,\n","         1.93446934e-01,  7.46859908e-01, -5.25200963e-01,\n","        -3.76857817e-02, -8.45910907e-01, -4.19703722e-02,\n","        -1.56721187e+00, -8.50432813e-01,  1.56626344e-01,\n","         1.65213346e-02, -5.36709726e-02, -7.28194475e-01,\n","        -4.28845942e-01,  1.51877731e-01,  9.38850641e-02,\n","        -2.27230549e-01,  1.96158886e-03, -8.43254447e-01,\n","         3.00073534e-01, -4.48408425e-01,  1.32451439e+00,\n","         1.43639773e-01,  1.30420208e+00,  4.98146772e-01,\n","         7.00252056e-01,  1.33368075e-01,  5.76908469e-01,\n","         3.02168369e-01,  1.26257491e+00,  1.03769600e+00,\n","         1.24960971e+00,  1.01403749e+00,  1.53706431e+00,\n","         8.34762454e-02,  4.49836314e-01,  7.12758005e-02,\n","         4.51373041e-01,  2.53641307e-02,  3.08014989e-01,\n","        -9.64534521e-01,  1.55991524e-01, -1.10083312e-01,\n","         6.35335565e-01,  1.41898882e+00,  3.80874813e-01,\n","        -6.54459596e-02, -5.03597736e-01,  2.65036494e-01,\n","         9.03867126e-01,  8.08184624e-01, -1.62893534e-01,\n","         9.99994874e-02,  5.32827616e-01,  9.78776336e-01,\n","        -1.27987921e-01,  1.34811652e+00, -6.72072113e-01,\n","        -2.95094907e-01, -1.22192240e+00, -2.87735462e-03,\n","        -1.81086349e+00,  6.27067447e-01,  1.32359207e-01,\n","         4.69239205e-02,  1.44673264e+00,  1.16238284e+00,\n","        -4.22278821e-01,  1.92915678e+00,  3.43165398e-01,\n","        -3.71318638e-01, -8.76001120e-02,  7.32243717e-01,\n","        -2.83339560e-01, -2.44901299e-01,  8.97148252e-01,\n","        -6.64315462e-01,  1.89034551e-01,  2.02290326e-01,\n","        -4.21275496e-02,  5.92555165e-01,  5.83173633e-01,\n","        -2.96976566e-01, -3.88868809e-01, -7.18874454e-01,\n","         1.25829530e+00,  1.60916412e+00,  1.77988029e+00,\n","        -3.14658582e-01,  9.12232339e-01,  1.24657035e-01,\n","         1.33339620e+00,  2.10769579e-01,  1.61560953e-01,\n","        -2.88296342e-02, -6.01445496e-01, -1.55524230e+00,\n","         7.54234195e-01,  1.42497754e+00,  1.22707114e-01,\n","         6.80063546e-01, -7.09320903e-02,  1.77703708e-01,\n","        -2.19703257e-01,  1.70994282e+00,  2.57787347e-01,\n","         9.18644905e-01,  1.39376676e+00,  1.64871895e+00,\n","         1.10351920e+00,  1.50849700e+00,  1.14854276e+00,\n","         1.58431494e+00,  6.55093431e-01,  9.88890111e-01,\n","         1.44025707e+00,  9.29606438e-01,  1.93535542e+00,\n","         4.87244099e-01,  1.28451276e+00,  8.48652303e-01,\n","         3.91460180e-01,  1.73308539e+00,  1.20319545e+00,\n","         9.32561636e-01,  1.08125138e+00,  7.69146562e-01,\n","        -3.70388031e-01,  1.41051948e+00,  7.09169745e-01,\n","         9.60532844e-01, -4.86689776e-01,  7.58096993e-01,\n","         2.29312062e-01, -8.05123448e-02,  6.47141278e-01,\n","         3.45649385e+00,  5.11621594e-01,  7.29883075e-01,\n","         7.32442737e-02,  6.52463436e-02,  1.45198452e+00,\n","        -9.51744556e-01,  5.15815377e-01,  2.04895228e-01,\n","         8.73620689e-01,  8.93728375e-01,  1.13065314e+00,\n","        -3.57445002e-01,  1.52675223e+00,  7.60865867e-01,\n","         1.30743921e-01,  6.93650246e-01,  5.86567402e-01,\n","         1.77408659e+00,  7.52225161e-01,  8.26818645e-02,\n","         1.41839051e+00,  1.71791649e+00,  9.37531531e-01,\n","         9.90324616e-01,  1.17459548e+00,  6.56314552e-01,\n","         7.22071409e-01,  1.61468410e+00,  8.00962299e-02,\n","         1.00066710e+00,  1.99547410e+00,  1.48898333e-01,\n","         9.26035762e-01,  2.02172160e+00,  1.39706993e+00,\n","         1.24998248e+00,  3.66560042e-01,  7.49525189e-01,\n","         1.47277308e+00,  1.63860291e-01,  1.22726309e+00,\n","         2.45083284e+00,  2.51977587e+00,  2.05765867e+00,\n","        -1.22971952e-01, -7.14923143e-01, -8.02923441e-02,\n","         8.98732781e-01,  1.57826948e+00,  2.39171338e+00,\n","         1.69910300e+00,  1.42741656e+00,  7.73081601e-01,\n","        -1.75040990e-01,  2.49267220e-02,  9.05416489e-01,\n","         2.66323733e+00,  1.28098583e+00, -7.07876444e-01,\n","         4.09974515e-01, -1.09937882e+00, -2.32992515e-01,\n","        -3.20174456e-01, -3.39415401e-01, -4.13199782e-01,\n","        -4.56918120e-01, -9.55004811e-01,  5.69433749e-01,\n","         9.16536212e-01,  9.99811232e-01,  4.10111129e-01,\n","         9.05361474e-01,  1.01141953e+00,  1.67374468e+00,\n","         1.04609525e+00,  7.08624721e-01, -2.19798654e-01,\n","        -4.38323289e-01,  1.34824264e+00,  1.15064669e+00,\n","         9.75522459e-01,  6.02924168e-01,  8.92919540e-01,\n","         3.58880639e-01,  2.97803581e-01,  6.39415324e-01,\n","         2.96175659e-01,  1.11454797e+00,  7.90797710e-01,\n","         8.53088677e-01, -5.32055259e-01, -1.16216910e+00,\n","         9.36451972e-01, -1.46017134e+00, -7.06002474e-01,\n","         1.30007207e+00, -1.35649249e-01,  1.82124674e-01,\n","         4.20332342e-01,  2.80977041e-01, -1.07485235e+00,\n","         1.38763952e+00,  6.07529402e-01, -6.94142163e-01,\n","         4.42670703e-01, -1.35110855e-01, -1.61229730e-01,\n","         5.88010967e-01,  1.21373928e+00,  2.07793713e-03,\n","         7.91998267e-01,  1.41228485e+00,  4.65626121e-01,\n","         7.01882958e-01, -3.53285462e-01,  1.73919439e-01,\n","        -2.09838629e-01,  3.77700567e-01, -1.34580374e-01,\n","        -3.95860553e-01,  4.44476783e-01,  1.06646359e+00,\n","         1.02706361e+00,  9.54069495e-01,  4.38257098e-01,\n","         9.79866087e-01,  6.14710629e-01,  1.88187551e+00,\n","         6.40997648e-01,  5.12552798e-01,  1.01736784e+00,\n","         1.25640130e+00,  5.14808297e-01, -9.77900505e-01,\n","        -9.33374524e-01,  3.99817467e-01,  4.45079446e-01,\n","        -8.73947620e-01,  3.69889617e-01, -5.71235478e-01,\n","         2.46199369e-01, -4.51208979e-01, -2.37493157e-01,\n","        -1.59663236e+00,  3.25349569e-01,  3.69411111e-02,\n","         1.30987793e-01, -7.80970335e-01,  5.01127005e-01,\n","        -1.13201916e-01,  5.41287720e-01,  6.10682368e-02,\n","         6.38978958e-01,  3.15769136e-01,  3.52600992e-01,\n","        -9.17859137e-01,  7.14847922e-01, -8.12795758e-03,\n","         3.40794921e-01,  7.68492460e-01, -7.21528053e-01,\n","         2.84874022e-01, -4.13280696e-01,  4.43705082e-01,\n","         9.40970063e-01,  4.50797707e-01, -1.03375459e+00,\n","         2.31023729e-01,  1.50772572e-01, -8.45586658e-02,\n","         2.50582457e-01, -5.20104170e-02, -6.84885979e-02,\n","        -9.93594527e-02, -7.94478297e-01, -9.14844871e-01,\n","        -5.87940395e-01,  3.14990044e-01, -1.11577606e+00,\n","         4.43354726e-01,  1.27083898e+00, -3.62958223e-01,\n","        -1.04358613e+00,  1.56455100e-01, -8.36796641e-01,\n","        -2.14248806e-01, -1.98889172e+00, -9.92588043e-01,\n","         4.85262334e-01, -2.44640872e-01, -7.07982004e-01,\n","        -5.24455070e-01, -7.26065397e-01, -4.31087911e-01,\n","        -6.12267852e-02, -5.67812264e-01,  2.11659670e-02,\n","        -8.08544517e-01, -8.13811600e-01, -9.67746079e-01,\n","        -1.08839464e+00, -1.69804978e+00, -1.21244133e-01,\n","         6.25755310e-01,  7.55392194e-01,  8.14937353e-01,\n","        -8.61989975e-01,  5.03498614e-01,  3.39502990e-02,\n","         5.02998710e-01, -1.98502675e-01, -8.95683646e-01,\n","         2.70584553e-01, -1.80931091e-01,  4.85610962e-01,\n","        -9.90521312e-02, -8.26467514e-01,  1.70090222e+00,\n","        -8.96148682e-02,  1.15692425e+00, -8.92438710e-01,\n","         2.61571616e-01, -2.64106274e-01,  1.08365655e+00,\n","        -8.37673843e-02,  2.83777833e-01,  4.29945529e-01,\n","         9.92276251e-01, -4.01419759e-01, -1.13862741e+00,\n","         4.63870823e-01,  2.47019932e-01, -3.97459149e-01,\n","         7.80407190e-02, -2.19147742e-01, -7.71713674e-01,\n","         7.52118453e-02, -4.30241346e-01, -2.85996675e-01,\n","         2.61653036e-01, -3.65084827e-01, -2.80163705e-01,\n","        -7.52145171e-01, -6.61570311e-01, -4.47451293e-01,\n","        -1.00938785e+00, -5.71542442e-01, -1.79047441e+00,\n","        -9.27545190e-01, -1.06469345e+00,  2.79221475e-01,\n","        -1.68487564e-01,  1.12524301e-01, -1.17027020e+00,\n","        -7.05599248e-01,  6.12526387e-02, -1.27140999e+00,\n","        -9.91818190e-01, -1.89072162e-01, -6.98049724e-01,\n","        -2.73980737e-01, -9.24466610e-01, -6.60118818e-01,\n","        -3.57370555e-01, -3.71842414e-01, -7.67582595e-01,\n","         9.19701934e-01,  5.00813961e-01, -5.93803644e-01,\n","         5.80208242e-01,  3.17069113e-01, -1.57331392e-01,\n","         8.70550334e-01,  6.88940287e-04,  1.44021499e+00,\n","        -2.65761644e-01,  9.55163181e-01,  1.38700950e+00,\n","         5.85093856e-01,  2.87218958e-01, -2.73963064e-01,\n","         6.87575340e-01, -1.43340588e-01,  1.03079236e+00,\n","        -4.00956720e-01,  5.80377638e-01,  1.59132481e+00,\n","         4.56627309e-02, -8.57769608e-01, -2.22927630e-02,\n","        -2.13050783e-01, -5.71997404e-01, -1.32709697e-01,\n","        -1.14090061e+00,  1.49500072e-02,  8.90167728e-02,\n","         5.53007722e-02, -2.20036089e-01,  4.65022504e-01,\n","        -3.56982648e-01,  2.18830705e-01,  1.31504089e-01,\n","        -1.32341301e+00, -1.28916860e+00, -1.04351521e-01,\n","        -2.38081992e-01,  4.49168414e-01,  2.88649350e-01,\n","        -9.47060227e-01,  2.14586318e-01,  5.02754867e-01,\n","         5.53373933e-01, -2.51661599e-01,  2.23677665e-01,\n","        -6.67993724e-02, -2.34503582e-01, -2.75059342e-01,\n","        -1.70944601e-01,  2.41912290e-01]], dtype=float32), past_key_values=None, decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=Array([[[-0.03629153,  0.00408451, -0.00104352, ...,  0.01352073,\n","         -0.000952  , -0.01271721],\n","        [ 0.01412584,  0.23138037,  0.43903878, ..., -0.26575541,\n","         -0.04425282,  0.5255758 ],\n","        [-0.2384166 ,  0.40880027,  0.05358759, ...,  0.1462898 ,\n","          0.14842239,  0.6388144 ],\n","        ...,\n","        [ 0.05689312,  0.24485968,  0.13947375, ..., -0.09632673,\n","         -0.07529559,  0.17911094],\n","        [ 0.42904767,  0.11805765, -0.08947601, ...,  0.179497  ,\n","          0.00239847,  0.21283685],\n","        [ 0.5111937 , -0.02182347,  0.2625382 , ..., -0.33367166,\n","          0.11277866, -0.01987655]]], dtype=float32), encoder_hidden_states=None, encoder_attentions=None)"]},"metadata":{},"execution_count":93}]},{"cell_type":"code","source":["def using_bart_models(ouputs, tokenizer):\n","\n","  start_scores = outputs.start_logits\n","  end_scores = outputs.end_logits\n","\n","  # start_logits = outputs.start_logits.squeeze()\n","  # end_logits = outputs.end_logits.squeeze()\n","\n","  # start_index = int(start_logits.argmax())\n","  # end_index = int(end_logits.argmax())\n","\n","  # tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'].squeeze())\n","  # answer_tokens = tokens[start_index : end_index + 1]\n","  # answer_text = tokenizer.decode(tokenizer.convert_tokens_to_ids(answer_tokens))\n","\n","  start_logits = outputs.start_logits.squeeze()\n","  end_logits = outputs.end_logits.squeeze()\n","\n","  start_index = int(start_logits.argmax())\n","  end_index = int(end_logits.argmax())\n","\n","  tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'].squeeze())\n","  answer_tokens = tokens[start_index + 1 : end_index + 1]  # Exclude the <s> token\n","  answer_text = tokenizer.decode(tokenizer.convert_tokens_to_ids(answer_tokens))"],"metadata":{"id":"6lNAKe_zR1tA","executionInfo":{"status":"ok","timestamp":1688196433560,"user_tz":-120,"elapsed":240,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}}},"execution_count":121,"outputs":[]},{"cell_type":"markdown","source":["# Question Answer Model - DistillBert"],"metadata":{"id":"fJRXhVDxWZ0v"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n","import torch\n","\n","# Load the pre-trained model and tokenizer\n","model_name = \"distilbert-base-uncased-distilled-squad\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n","\n","def answer_question(question, text):\n","    # Tokenize input question and text\n","    inputs = tokenizer(question, text, return_tensors='pt', truncation=True)\n","\n","    # Perform question-answering\n","    start_positions, end_positions = model(**inputs).values()\n","\n","    # Find the predicted answer span\n","    answer_start = torch.argmax(start_positions, dim=1).item()\n","    answer_end = torch.argmax(end_positions, dim=1).item()\n","\n","    # Decode the answer tokens\n","    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n","    answer = tokenizer.convert_tokens_to_string(tokens[answer_start:answer_end+1])\n","\n","    return answer\n","\n","# Example usage\n","question = \"What is the capital of France?\"\n","text = \"France is a country located in Western Europe. Its capital is Paris.\"\n","answer = answer_question(question, text)\n","print(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fq1JoBs2TavT","executionInfo":{"status":"ok","timestamp":1688196132715,"user_tz":-120,"elapsed":4479,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"dc144b31-6c2e-40d9-b311-02c2f63f8678"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["paris\n"]}]},{"cell_type":"markdown","source":[" # Combine Everything together -> Embedding, Retriever and QA"],"metadata":{"id":"ktaEqxMRWelK"}},{"cell_type":"code","source":["query = \"what are chatbots\"\n","response_text, response_title = get_top_k_text(articles, 5, query)\n","top_k_document_text = \" \".join(response_text)\n","answer = answer_question(query, top_k_document_text)\n","print(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YtRYa9p-WdoV","executionInfo":{"status":"ok","timestamp":1688198016361,"user_tz":-120,"elapsed":1802,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"b7f629f0-06fe-4c75-86b3-510c40e7680a"},"execution_count":153,"outputs":[{"output_type":"stream","name":"stdout","text":["a service, powered by rules and sometimes artificial intelligence, that you interact with via a chat interface. the service could be any number of things, ranging from functional to fun, and it could live in any major chat product ( facebook messenger, slack, telegram, text messages, etc. ). if you haven ’ t wrapped your head around it yet, don ’ t worry. here ’ s an example to help you visualize a chatbot. if you wanted to buy shoes from nordstrom online, you would go to their website, look around until you find the shoes you wanted, and then you would purchase them. if nordstrom makes a bot, which i ’ m sure they will, you would simply be able to message nordstrom on facebook. it would ask you what you ’ re looking for and you would simply... tell it. instead of browsing a website, you will have a conversation with the nordstrom bot, mirroring the type of experience you would get when you go into the retail store. watch this video from facebook ’ s recent f8 conference ( where they make their major announcements ). at the 7 : 30 mark, david marcus, the vice president of messaging products at facebook, explains what it looks like to buy shoes in a facebook messenger bot. buying shoes isn ’ t the only thing chatbots can be used for. here are a couple of other examples : see? with bots, the possibilities are endless. you can build anything imaginable, and i encourage you to do just that. but why make a bot? sure, it looks cool, it ’ s using some super advanced technology, but why should someone spend their time and energy on it? it ’ s a huge opportunity. huge. scroll down\n"]}]},{"cell_type":"code","source":["top_k_document_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"spZ0JIqwcY03","executionInfo":{"status":"ok","timestamp":1688198025982,"user_tz":-120,"elapsed":265,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"bd96964a-ca02-4274-b668-391ad7df54a0"},"execution_count":154,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"What are chatbots? Why are they such a big opportunity? How do they work? How can I build one? How can I meet other people interested in chatbots?\\nThese are the questions we’re going to answer for you right now.\\nReady? Let’s do this.\\n(Do you work in ecommerce? Stop reading and click here, we made something for you.)\\n(p.s. here is where I believe the future of bots is headed, you will probably disagree with me at first.)\\n(p.p.s. My newest guide about conversational commerce is up, I think you’ll find it super interesting.)\\nA chatbot is a service, powered by rules and sometimes artificial intelligence, that you interact with via a chat interface. The service could be any number of things, ranging from functional to fun, and it could live in any major chat product (Facebook Messenger, Slack, Telegram, Text Messages, etc.).\\nIf you haven’t wrapped your head around it yet, don’t worry. Here’s an example to help you visualize a chatbot.\\nIf you wanted to buy shoes from Nordstrom online, you would go to their website, look around until you find the shoes you wanted, and then you would purchase them.\\nIf Nordstrom makes a bot, which I’m sure they will, you would simply be able to message Nordstrom on Facebook. It would ask you what you’re looking for and you would simply... tell it.\\nInstead of browsing a website, you will have a conversation with the Nordstrom bot, mirroring the type of experience you would get when you go into the retail store.\\nWatch this video from Facebook’s recent F8 conference (where they make their major announcements). At the 7:30 mark, David Marcus, the Vice President of Messaging Products at Facebook, explains what it looks like to buy shoes in a Facebook Messenger bot.\\nBuying shoes isn’t the only thing chatbots can be used for. Here are a couple of other examples:\\nSee? With bots, the possibilities are endless. You can build anything imaginable, and I encourage you to do just that.\\nBut why make a bot? Sure, it looks cool, it’s using some super advanced technology, but why should someone spend their time and energy on it?\\nIt’s a huge opportunity. HUGE. Scroll down and I’ll explain.\\nYou are probably wondering “Why does anyone care about chatbots? They look like simple text based services... what’s the big deal?”\\nGreat question. I’ll tell you why people care about chatbots.\\nIt’s because for the first time ever people are using messenger apps more than they are using social networks.\\nLet that sink in for a second.\\nPeople are using messenger apps more than they are using social networks.\\nSo, logically, if you want to build a business online, you want to build where the people are. That place is now inside messenger apps.\\nThis is why chatbots are such a big deal. It’s potentially a huge business opportunity for anyone willing to jump headfirst and build something people want.\\nBut, how do these bots work? How do they know how to talk to people and answer questions? Isn’t that artificial intelligence and isn’t that insanely hard to do?\\nYes, you are correct, it is artificial intelligence, but it’s something that you can totally do yourself.\\nLet me explain.\\nThere are two types of chatbots, one functions based on a set of rules, and the other more advanced version uses machine learning.\\nWhat does this mean?\\nChatbot that functions based on rules:\\nChatbot that functions using machine learning:\\nBots are created with a purpose. A store will likely want to create a bot that helps you purchase something, where someone like Comcast might create a bot that can answer customer support questions.\\nYou start to interact with a chatbot by sending it a message. Click here to try sending a message to the CNN chatbot on Facebook.\\nSo, if these bots use artificial intelligence to make them work well... isn’t that really hard to do? Don’t I need to be an expert at artificial intelligence to be able to build something that has artificial intelligence?\\nShort answer? No, you don’t have to be an expert at artificial intelligence to create an awesome chatbot that has artificial intelligence. Just make sure to not over promise on your application’s abilities. If you can’t make the product good with artificial intelligence right now, it might be best to not put it in yet.\\nHowever, over the past decade quite a bit of advancements have been made in the area of artificial intelligence, so much in fact that anyone who knows how to code can incorporate some level of artificial intelligence into their products.\\nHow do you build artificial intelligence into your bot? Don’t worry, I’ve got you covered, I’ll tell you how to do it in the next section of this post.\\nBuilding a chatbot can sound daunting, but it’s totally doable. You’ll be creating an artificial intelligence powered chatting machine in no time (or, of course, you can always build a basic chat bot that doesn’t have a fancy AI brain and strictly follows rules).\\nYou will need to figure out what problem you are going to solve with your bot, choose which platform your bot will live on (Facebook, Slack, etc), set up a server to run your bot from, and choose which service you will use to build your bot.\\nHere are a ton of resources to get you started.\\nPlatform documentation:\\nOther Resources:\\nDon’t want to build your own?\\nNow that you’ve got your chatbot and artificial intelligence resources, maybe it’s time you met other people who are also interested in chatbots.\\nChatbots have been around for decades, but because of the recent advancements in artificial intelligence and machine learning, there is a big opportunity for people to create bots that are better, faster, and stronger.\\nIf you’re reading this, you probably fall into one of these categories:\\nWouldn’t it be awesome if you had a place to meet, learn, and share information with other people interested in chatbots? Yeah, we thought so too.\\nThat’s why I created a forum called “Chatbot News”, and it has quickly become the largest community related to Chatbots.\\nThe members of the Chatbots group are investors who manage well over $2 billion in capital, employees at Facebook, Instagram, Fitbit, Nike, and Ycombinator companies, and hackers from around the world.\\nWe would love if you joined. Click here to request an invite private chatbots community.\\nI have also created the Silicon Valley Chatbots Meetup, register here to be notified when we schedule our first event.\\nFrom a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\\nCEO of Octane AI, Founder of Chatbots Magazine, YC Alum, Forbes 30 Under 30, product at Ustream for 4 years (sold for $130mil), did digital for Lil Wayne.\\nChatbots, AI, NLP, Facebook Messenger, Slack, Telegram, and more.\\n Oh, how the headlines blared:\\nChatbots were The Next Big Thing.\\nOur hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.\\nAnd why wouldn’t they be? All the road signs pointed towards insane success.\\nAt the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’.\\nIn fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place:\\nOne year on, we have an answer to that question.\\nNo.\\nBecause there isn’t even an ecosystem for a platform to dominate.\\nChatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly.\\nThe age-old hype cycle unfolded in familiar fashion...\\nExpectations built, built, and then..... It all kind of fizzled out.\\nThe predicted paradim shift didn’t materialize.\\nAnd apps are, tellingly, still alive and well.\\nWe look back at our breathless optimism and turn to each other, slightly baffled:\\n“is that it? THAT was the chatbot revolution we were promised?”\\nDigit’s Ethan Bloch sums up the general consensus:\\nAccording to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail: they took on several and failed all of them.\\nBots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word.\\nUsers had to type commands manually into a machine to get anything done.\\nThen, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too!\\nMeanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language.\\nAnother bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised:\\nThe next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system:\\nPretty cool, right? The system takes turns in collaborative way, and does a smart job of figuring out what the user wants.\\nIt was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations.\\nModern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms.\\nBasically, we’re still trying to achieve the same innovations we were 30 years ago.\\nHere’s where I think we’re going wrong:\\nAn oversized assumption has been that apps are ‘over’, and would be replaced by bots.\\nBy pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development.\\nYou might remember a similar war cry when apps first came onto the scene ten years ago: but do you remember when apps replaced the internet?\\nIt’s said that a new product or service needs to be two of the following: better, cheaper, or faster. Are chatbots cheaper or faster than apps? No — not yet, at least.\\nWhether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app.\\nPlus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail.\\nA great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition.\\nThat’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems.\\nModern-day apps benefit from decades of research and experimentation. Why would we throw this away?\\nBut, if we swap the word ‘replace’ with ‘extend’, things get much more interesting.\\nToday’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements.\\nThe next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.\\nAnother problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these.\\nFor plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed.\\nBuilding a bot for the sake of it, letting it loose and hoping for the best will never end well:\\nThe vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.\\nThe advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too.\\nThat’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate.\\nProblems arise when life refuses to fit into those boxes.\\nAccording to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus.\\nWhen we were building GrowthBot, we decided to make it specific to sales and marketers: not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties.\\nRemember: a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly.\\nA competent developer can build a basic bot in minutes — but one that can hold a conversation? That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like.\\nIn an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy.\\nSome platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.)\\nAs Matt Asay outlines, this results in another issue: failure to capture the attention and creativity of developers.\\nAnd conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish.\\nToday’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet.\\nAnd in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked:\\nOnce upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate information\\nThere’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type.\\nTapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true.\\nWe love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication.\\nConversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative.\\nSure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.\\nAiming for a human dimension in business interactions makes sense.\\nIf there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.\\nFacebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.\\nA conversation encompasses so much more than just text.\\nHumans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.\\nAs HubSpot team pinpointed:\\nPeople aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).\\nAnd even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.\\nAnd here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.\\nBut is that how humans prefer to interact with machines?\\nNot necessarily.\\nAt the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.\\nIn a way, those early-adopters weren’t entirely wrong.\\nPeople are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.\\nNot even close.\\nComputers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information.\\nComputers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel.\\nThat’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch: empathy and emotional intelligence.\\nFor now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon.\\nBut that’s not the whole story.\\nYes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial.\\nAs Bill Gates once said:\\nThe hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone.\\nI believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology.\\nMessaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day.\\nDevelopers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing.\\nAnd I can’t wait to see what happens next.\\nFrom a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\\nHead of Growth for GrowthBot, Messaging & Conversational Strategy @HubSpot\\nMedium's largest publication for makers. Subscribe to receive our top stories here → https://goo.gl/zHcLJi\\n Oh, how the headlines blared:\\nChatbots were The Next Big Thing.\\nOur hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.\\nAnd why wouldn’t they be? All the road signs pointed towards insane success.\\nAt the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’.\\nIn fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place:\\nOne year on, we have an answer to that question.\\nNo.\\nBecause there isn’t even an ecosystem for a platform to dominate.\\nChatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly.\\nThe age-old hype cycle unfolded in familiar fashion...\\nExpectations built, built, and then..... It all kind of fizzled out.\\nThe predicted paradim shift didn’t materialize.\\nAnd apps are, tellingly, still alive and well.\\nWe look back at our breathless optimism and turn to each other, slightly baffled:\\n“is that it? THAT was the chatbot revolution we were promised?”\\nDigit’s Ethan Bloch sums up the general consensus:\\nAccording to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail: they took on several and failed all of them.\\nBots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word.\\nUsers had to type commands manually into a machine to get anything done.\\nThen, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too!\\nMeanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language.\\nAnother bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised:\\nThe next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system:\\nPretty cool, right? The system takes turns in collaborative way, and does a smart job of figuring out what the user wants.\\nIt was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations.\\nModern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms.\\nBasically, we’re still trying to achieve the same innovations we were 30 years ago.\\nHere’s where I think we’re going wrong:\\nAn oversized assumption has been that apps are ‘over’, and would be replaced by bots.\\nBy pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development.\\nYou might remember a similar war cry when apps first came onto the scene ten years ago: but do you remember when apps replaced the internet?\\nIt’s said that a new product or service needs to be two of the following: better, cheaper, or faster. Are chatbots cheaper or faster than apps? No — not yet, at least.\\nWhether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app.\\nPlus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail.\\nA great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition.\\nThat’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems.\\nModern-day apps benefit from decades of research and experimentation. Why would we throw this away?\\nBut, if we swap the word ‘replace’ with ‘extend’, things get much more interesting.\\nToday’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements.\\nThe next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.\\nAnother problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these.\\nFor plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed.\\nBuilding a bot for the sake of it, letting it loose and hoping for the best will never end well:\\nThe vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.\\nThe advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too.\\nThat’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate.\\nProblems arise when life refuses to fit into those boxes.\\nAccording to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus.\\nWhen we were building GrowthBot, we decided to make it specific to sales and marketers: not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties.\\nRemember: a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly.\\nA competent developer can build a basic bot in minutes — but one that can hold a conversation? That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like.\\nIn an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy.\\nSome platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.)\\nAs Matt Asay outlines, this results in another issue: failure to capture the attention and creativity of developers.\\nAnd conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish.\\nToday’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet.\\nAnd in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked:\\nOnce upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate information\\nThere’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type.\\nTapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true.\\nWe love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication.\\nConversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative.\\nSure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.\\nAiming for a human dimension in business interactions makes sense.\\nIf there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.\\nFacebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.\\nA conversation encompasses so much more than just text.\\nHumans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.\\nAs HubSpot team pinpointed:\\nPeople aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).\\nAnd even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.\\nAnd here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.\\nBut is that how humans prefer to interact with machines?\\nNot necessarily.\\nAt the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.\\nIn a way, those early-adopters weren’t entirely wrong.\\nPeople are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.\\nNot even close.\\nComputers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information.\\nComputers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel.\\nThat’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch: empathy and emotional intelligence.\\nFor now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon.\\nBut that’s not the whole story.\\nYes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial.\\nAs Bill Gates once said:\\nThe hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone.\\nI believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology.\\nMessaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day.\\nDevelopers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing.\\nAnd I can’t wait to see what happens next.\\nFrom a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\\nHead of Growth for GrowthBot, Messaging & Conversational Strategy @HubSpot\\nMedium's largest publication for makers. Subscribe to receive our top stories here → https://goo.gl/zHcLJi\\n Oh, how the headlines blared:\\nChatbots were The Next Big Thing.\\nOur hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.\\nAnd why wouldn’t they be? All the road signs pointed towards insane success.\\nAt the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’.\\nIn fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place:\\nOne year on, we have an answer to that question.\\nNo.\\nBecause there isn’t even an ecosystem for a platform to dominate.\\nChatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly.\\nThe age-old hype cycle unfolded in familiar fashion...\\nExpectations built, built, and then..... It all kind of fizzled out.\\nThe predicted paradim shift didn’t materialize.\\nAnd apps are, tellingly, still alive and well.\\nWe look back at our breathless optimism and turn to each other, slightly baffled:\\n“is that it? THAT was the chatbot revolution we were promised?”\\nDigit’s Ethan Bloch sums up the general consensus:\\nAccording to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail: they took on several and failed all of them.\\nBots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word.\\nUsers had to type commands manually into a machine to get anything done.\\nThen, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too!\\nMeanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language.\\nAnother bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised:\\nThe next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system:\\nPretty cool, right? The system takes turns in collaborative way, and does a smart job of figuring out what the user wants.\\nIt was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations.\\nModern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms.\\nBasically, we’re still trying to achieve the same innovations we were 30 years ago.\\nHere’s where I think we’re going wrong:\\nAn oversized assumption has been that apps are ‘over’, and would be replaced by bots.\\nBy pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development.\\nYou might remember a similar war cry when apps first came onto the scene ten years ago: but do you remember when apps replaced the internet?\\nIt’s said that a new product or service needs to be two of the following: better, cheaper, or faster. Are chatbots cheaper or faster than apps? No — not yet, at least.\\nWhether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app.\\nPlus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail.\\nA great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition.\\nThat’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems.\\nModern-day apps benefit from decades of research and experimentation. Why would we throw this away?\\nBut, if we swap the word ‘replace’ with ‘extend’, things get much more interesting.\\nToday’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements.\\nThe next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.\\nAnother problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these.\\nFor plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed.\\nBuilding a bot for the sake of it, letting it loose and hoping for the best will never end well:\\nThe vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.\\nThe advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too.\\nThat’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate.\\nProblems arise when life refuses to fit into those boxes.\\nAccording to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus.\\nWhen we were building GrowthBot, we decided to make it specific to sales and marketers: not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties.\\nRemember: a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly.\\nA competent developer can build a basic bot in minutes — but one that can hold a conversation? That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like.\\nIn an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy.\\nSome platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.)\\nAs Matt Asay outlines, this results in another issue: failure to capture the attention and creativity of developers.\\nAnd conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish.\\nToday’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet.\\nAnd in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked:\\nOnce upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate information\\nThere’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type.\\nTapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true.\\nWe love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication.\\nConversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative.\\nSure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.\\nAiming for a human dimension in business interactions makes sense.\\nIf there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.\\nFacebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.\\nA conversation encompasses so much more than just text.\\nHumans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.\\nAs HubSpot team pinpointed:\\nPeople aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).\\nAnd even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.\\nAnd here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.\\nBut is that how humans prefer to interact with machines?\\nNot necessarily.\\nAt the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.\\nIn a way, those early-adopters weren’t entirely wrong.\\nPeople are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.\\nNot even close.\\nComputers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information.\\nComputers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel.\\nThat’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch: empathy and emotional intelligence.\\nFor now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon.\\nBut that’s not the whole story.\\nYes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial.\\nAs Bill Gates once said:\\nThe hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone.\\nI believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology.\\nMessaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day.\\nDevelopers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing.\\nAnd I can’t wait to see what happens next.\\nFrom a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\\nHead of Growth for GrowthBot, Messaging & Conversational Strategy @HubSpot\\nMedium's largest publication for makers. Subscribe to receive our top stories here → https://goo.gl/zHcLJi\\n How do we define the intelligence of a chatbot? You can see a lot of articles about what would make a chatbot “appear intelligent.” A chatbot is intelligent when it becomes aware of user needs. Its intelligence is what gives the chatbot the ability to handle any scenario of a conversation with ease.\\nAre the travel bots or the weather bots that have buttons that you click and give you some query, artificially intelligent? Definitely, but they are just not far along the conversation axis. It can be a wonderfully designed conversational interface that is smooth and easy to use. It could be natural language processing and understanding where it is able to understand sentences that you structure in the wrong way. Now, it is easier than ever to make a bot from scratch. Also chatbot development platforms like Chatfuel, Gupshup make it fairly simple to build a chatbot without a technical background. Hence, making the reach for chatbot easy and transparent to anyone who would like to have one for their business. For more understanding on intelligent chatbots, read our blog.\\nThe best AI based chatbots available online are Mitsuku, Rose, Poncho, Right Click, Insomno Bot, Dr. AI and Melody.\\nThis chatbot is one the best AI chatbots and it’s my favorite too. Evidently it is the current winner of Loebner Prize. The Loebner Prize is an annual competition in artificial intelligence that awards prizes to the chatterbot considered by the judges to be the most human-like. The format of the competition is that of a standard Turing test. You can talk with Mitsuku for hours without getting bored. It replies to your question in the most humane way and understands your mood with the language you’re using.\\nIt is a bot made to chat about anything, which is one of the main reasons that make it so human-like — contrary to other chatbots that are made for a specific task.\\nRose is a chatbot, and a very good one — she won recognition this past Saturday as the most human-like chatbot in a competition described as the first Turing test, the Loebner Prize in 2014 and 2015.\\nRight Click is a startup that introduced an A.I.-powered chatbot that creates websites. It asks general questions during the conversation like “What industry you belong to?” and “Why do you want to make a website?” and creates customized templates as per the given answers. Hira Saeed tried to divert it from its job by asking it about love, but what a smart player it is! By replying to each of her queries, it tried to bring her back to the actual job of website creation. The process was short but keeps you hooked.\\nPoncho is a Messenger bot designed to be your one and only weather expert. It sends alerts up to twice a day with user consent and is intelligent enough to answer questions like “Should I take an umbrella today?”\\nRead Poncho developer’s piece: Think Differently When Building Bots\\nInsomno bot is for night owls. As the name suggests, it is for all people out there who have trouble sleeping. This bot talks to you when you have no one around and gives you amazing replies so that you won’t get bored. It’s not something that will help you count stars when you can’t sleep or help you with reading suggestions, but this bot talks to you about anything.\\nIt asks about symptoms, body parameters and medical history, then compiles a list of the most and least likely causes for the symptoms and ranks them by order of seriousness.\\nIt lives inside the existing Biadu Doctor app. This app collects medical information from people and then passes it to doctors in a form that makes it easier to use for diagnostic purposes or to otherwise respond to.\\nFeatured CBM: The Future, Healthcare, and Conversational UI\\nThese are just the basic versions of intelligent chatbots. There are many more intelligent chatbots out there which provide a much more smarter approach to responding to queries. Since the process of making a intelligent chatbot is not a big task, most of us can achieve it with the most basic technical knowledge. Many of which will be very extremely helpful in the service industry and also help provide a better customer experience.\\nThe most important part of any chatbot is the conversation it has with its user. Hence, more effort has to be put in designing a chatbot conversation. Hope you had a good read. To know more about Chatbots and how they converse with people, visit the link below.\\nFeatured CBM: How to Make a Chatbot Intelligent?\\nIf you resonated with this article, please subscribe to our newsletter. You will get a free copy of our Case Study on Business Automation through our Bot solution.\\nFrom a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\\nProfessional team delivering enterprise software solutions — Bot development, Big Data Analytics, Web & Mobile Apps, and AI & ML integration.\\nChatbots, AI, NLP, Facebook Messenger, Slack, Telegram, and more.\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":154}]},{"cell_type":"code","source":["articles.tail(20)[\"title\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u1nDl1UhYPx9","executionInfo":{"status":"ok","timestamp":1688197161954,"user_tz":-120,"elapsed":258,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"90cdc619-e783-4fc3-e950-847ac6e6e847"},"execution_count":143,"outputs":[{"output_type":"execute_result","data":{"text/plain":["317    Traffic Sign Recognition with TensorFlow – Wal...\n","318    Cheat Sheets for AI, Neural Networks, Machine ...\n","319    Understanding Activation Functions in Neural N...\n","320    Romance Novels, Generated by Artificial Intell...\n","321    37 Reasons why your Neural Network is not work...\n","322               Picking a GPU for Deep Learning – Slav\n","323    Text Classification using Neural Networks – Ma...\n","324    You requested someone with a degree in this? *...\n","325    A Guide For Time Series Prediction Using Recur...\n","326    Neural Network Architectures – Towards Data Sc...\n","327    In defense of skepticism about deep learning –...\n","328    How to easily Detect Objects with Deep Learnin...\n","329    A “weird” introduction to Deep Learning – Towa...\n","330      The New Neural Internet is Coming – Hacker Noon\n","331    Stochastic Weight Averaging — a New Way to Get...\n","332    You can build a neural network in JavaScript e...\n","333    Artificial Intelligence, AI in 2018 and beyond...\n","334    Spiking Neural Networks, the Next Generation o...\n","335    Surprise! Neurons are Now More Complex than We...\n","336    “WTH does a neural network even learn??” — a n...\n","Name: title, dtype: object"]},"metadata":{},"execution_count":143}]},{"cell_type":"code","source":["query = \"How to easily Detect Objects with Deep Learning\"\n","response_text, response_title = get_top_k_text(articles, 5, query)\n","top_k_document_text = \" \".join(response_text)\n","answer = answer_question(query, top_k_document_text)\n","print(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IRhDP_VvW1Ec","executionInfo":{"status":"ok","timestamp":1688197009325,"user_tz":-120,"elapsed":2538,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"c9efc1e5-8ab5-456a-9725-2297c6054f32"},"execution_count":135,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS]\n"]}]},{"cell_type":"code","source":["query = \"What is AI ?\"\n","response_text, response_title = get_top_k_text(articles, 5, query)\n","top_k_document_text = \" \".join(response_text)\n","answer = answer_question(query, top_k_document_text)\n","print(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zPgTTgnNYYSz","executionInfo":{"status":"ok","timestamp":1688198070947,"user_tz":-120,"elapsed":1981,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"d082142d-ddb1-4802-9022-a94a8d2fe2ac"},"execution_count":155,"outputs":[{"output_type":"stream","name":"stdout","text":["artificial intelligence\n"]}]},{"cell_type":"code","source":["top_k_document_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"E5iF6kXGYmTo","executionInfo":{"status":"ok","timestamp":1688197089445,"user_tz":-120,"elapsed":280,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"6006aafc-dec4-4340-f066-93f471e7638d"},"execution_count":142,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Artificial Intelligence (AI) is the mantra of the current era. The phrase is intoned by technologists, academicians, journalists and venture capitalists alike. As with many phrases that cross over from technical academic fields into general circulation, there is significant misunderstanding accompanying the use of the phrase. But this is not the classical case of the public not understanding the scientists — here the scientists are often as befuddled as the public. The idea that our era is somehow seeing the emergence of an intelligence in silicon that rivals our own entertains all of us — enthralling us and frightening us in equal measure. And, unfortunately, it distracts us.\\nThere is a different narrative that one can tell about the current era. Consider the following story, which involves humans, computers, data and life-or-death decisions, but where the focus is something other than intelligence-in-silicon fantasies. When my spouse was pregnant 14 years ago, we had an ultrasound. There was a geneticist in the room, and she pointed out some white spots around the heart of the fetus. “Those are markers for Down syndrome,” she noted, “and your risk has now gone up to 1 in 20.” She further let us know that we could learn whether the fetus in fact had the genetic modification underlying Down syndrome via an amniocentesis. But amniocentesis was risky — the risk of killing the fetus during the procedure was roughly 1 in 300. Being a statistician, I determined to find out where these numbers were coming from. To cut a long story short, I discovered that a statistical analysis had been done a decade previously in the UK, where these white spots, which reflect calcium buildup, were indeed established as a predictor of Down syndrome. But I also noticed that the imaging machine used in our test had a few hundred more pixels per square inch than the machine used in the UK study. I went back to tell the geneticist that I believed that the white spots were likely false positives — that they were literally “white noise.” She said “Ah, that explains why we started seeing an uptick in Down syndrome diagnoses a few years ago; it’s when the new machine arrived.”\\nWe didn’t do the amniocentesis, and a healthy girl was born a few months later. But the episode troubled me, particularly after a back-of-the-envelope calculation convinced me that many thousands of people had gotten that diagnosis that same day worldwide, that many of them had opted for amniocentesis, and that a number of babies had died needlessly. And this happened day after day until it somehow got fixed. The problem that this episode revealed wasn’t about my individual medical care; it was about a medical system that measured variables and outcomes in various places and times, conducted statistical analyses, and made use of the results in other places and times. The problem had to do not just with data analysis per se, but with what database researchers call “provenance” — broadly, where did data arise, what inferences were drawn from the data, and how relevant are those inferences to the present situation? While a trained human might be able to work all of this out on a case-by-case basis, the issue was that of designing a planetary-scale medical system that could do this without the need for such detailed human oversight.\\nI’m also a computer scientist, and it occurred to me that the principles needed to build planetary-scale inference-and-decision-making systems of this kind, blending computer science with statistics, and taking into account human utilities, were nowhere to be found in my education. And it occurred to me that the development of such principles — which will be needed not only in the medical domain but also in domains such as commerce, transportation and education — were at least as important as those of building AI systems that can dazzle us with their game-playing or sensorimotor skills.\\nWhether or not we come to understand “intelligence” any time soon, we do have a major challenge on our hands in bringing together computers and humans in ways that enhance human life. While this challenge is viewed by some as subservient to the creation of “artificial intelligence,” it can also be viewed more prosaically — but with no less reverence — as the creation of a new branch of engineering. Much like civil engineering and chemical engineering in decades past, this new discipline aims to corral the power of a few key ideas, bringing new resources and capabilities to people, and doing so safely. Whereas civil engineering and chemical engineering were built on physics and chemistry, this new engineering discipline will be built on ideas that the preceding century gave substance to — ideas such as “information,” “algorithm,” “data,” “uncertainty,” “computing,” “inference,” and “optimization.” Moreover, since much of the focus of the new discipline will be on data from and about humans, its development will require perspectives from the social sciences and humanities.\\nWhile the building blocks have begun to emerge, the principles for putting these blocks together have not yet emerged, and so the blocks are currently being put together in ad-hoc ways.\\nThus, just as humans built buildings and bridges before there was civil engineering, humans are proceeding with the building of societal-scale, inference-and-decision-making systems that involve machines, humans and the environment. Just as early buildings and bridges sometimes fell to the ground — in unforeseen ways and with tragic consequences — many of our early societal-scale inference-and-decision-making systems are already exposing serious conceptual flaws.\\nAnd, unfortunately, we are not very good at anticipating what the next emerging serious flaw will be. What we’re missing is an engineering discipline with its principles of analysis and design.\\nThe current public dialog about these issues too often uses “AI” as an intellectual wildcard, one that makes it difficult to reason about the scope and consequences of emerging technology. Let us begin by considering more carefully what “AI” has been used to refer to, both recently and historically.\\nMost of what is being called “AI” today, particularly in the public sphere, is what has been called “Machine Learning” (ML) for the past several decades. ML is an algorithmic field that blends ideas from statistics, computer science and many other disciplines (see below) to design algorithms that process data, make predictions and help make decisions. In terms of impact on the real world, ML is the real thing, and not just recently. Indeed, that ML would grow into massive industrial relevance was already clear in the early 1990s, and by the turn of the century forward-looking companies such as Amazon were already using ML throughout their business, solving mission-critical back-end problems in fraud detection and supply-chain prediction, and building innovative consumer-facing services such as recommendation systems. As datasets and computing resources grew rapidly over the ensuing two decades, it became clear that ML would soon power not only Amazon but essentially any company in which decisions could be tied to large-scale data. New business models would emerge. The phrase “Data Science” began to be used to refer to this phenomenon, reflecting the need of ML algorithms experts to partner with database and distributed-systems experts to build scalable, robust ML systems, and reflecting the larger social and environmental scope of the resulting systems.\\nThis confluence of ideas and technology trends has been rebranded as “AI” over the past few years. This rebranding is worthy of some scrutiny.\\nHistorically, the phrase “AI” was coined in the late 1950’s to refer to the heady aspiration of realizing in software and hardware an entity possessing human-level intelligence. We will use the phrase “human-imitative AI” to refer to this aspiration, emphasizing the notion that the artificially intelligent entity should seem to be one of us, if not physically at least mentally (whatever that might mean). This was largely an academic enterprise. While related academic fields such as operations research, statistics, pattern recognition, information theory and control theory already existed, and were often inspired by human intelligence (and animal intelligence), these fields were arguably focused on “low-level” signals and decisions. The ability of, say, a squirrel to perceive the three-dimensional structure of the forest it lives in, and to leap among its branches, was inspirational to these fields. “AI” was meant to focus on something different — the “high-level” or “cognitive” capability of humans to “reason” and to “think.” Sixty years later, however, high-level reasoning and thought remain elusive. The developments which are now being called “AI” arose mostly in the engineering fields associated with low-level pattern recognition and movement control, and in the field of statistics — the discipline focused on finding patterns in data and on making well-founded predictions, tests of hypotheses and decisions.\\nIndeed, the famous “backpropagation” algorithm that was rediscovered by David Rumelhart in the early 1980s, and which is now viewed as being at the core of the so-called “AI revolution,” first arose in the field of control theory in the 1950s and 1960s. One of its early applications was to optimize the thrusts of the Apollo spaceships as they headed towards the moon.\\nSince the 1960s much progress has been made, but it has arguably not come about from the pursuit of human-imitative AI. Rather, as in the case of the Apollo spaceships, these ideas have often been hidden behind the scenes, and have been the handiwork of researchers focused on specific engineering challenges. Although not visible to the general public, research and systems-building in areas such as document retrieval, text classification, fraud detection, recommendation systems, personalized search, social network analysis, planning, diagnostics and A/B testing have been a major success — these are the advances that have powered companies such as Google, Netflix, Facebook and Amazon.\\nOne could simply agree to refer to all of this as “AI,” and indeed that is what appears to have happened. Such labeling may come as a surprise to optimization or statistics researchers, who wake up to find themselves suddenly referred to as “AI researchers.” But labeling of researchers aside, the bigger problem is that the use of this single, ill-defined acronym prevents a clear understanding of the range of intellectual and commercial issues at play.\\nThe past two decades have seen major progress — in industry and academia — in a complementary aspiration to human-imitative AI that is often referred to as “Intelligence Augmentation” (IA). Here computation and data are used to create services that augment human intelligence and creativity. A search engine can be viewed as an example of IA (it augments human memory and factual knowledge), as can natural language translation (it augments the ability of a human to communicate). Computing-based generation of sounds and images serves as a palette and creativity enhancer for artists. While services of this kind could conceivably involve high-level reasoning and thought, currently they don’t — they mostly perform various kinds of string-matching and numerical operations that capture patterns that humans can make use of.\\nHoping that the reader will tolerate one last acronym, let us conceive broadly of a discipline of “Intelligent Infrastructure” (II), whereby a web of computation, data and physical entities exists that makes human environments more supportive, interesting and safe. Such infrastructure is beginning to make its appearance in domains such as transportation, medicine, commerce and finance, with vast implications for individual humans and societies. This emergence sometimes arises in conversations about an “Internet of Things,” but that effort generally refers to the mere problem of getting “things” onto the Internet — not to the far grander set of challenges associated with these “things” capable of analyzing those data streams to discover facts about the world, and interacting with humans and other “things” at a far higher level of abstraction than mere bits.\\nFor example, returning to my personal anecdote, we might imagine living our lives in a “societal-scale medical system” that sets up data flows, and data-analysis flows, between doctors and devices positioned in and around human bodies, thereby able to aid human intelligence in making diagnoses and providing care. The system would incorporate information from cells in the body, DNA, blood tests, environment, population genetics and the vast scientific literature on drugs and treatments. It would not just focus on a single patient and a doctor, but on relationships among all humans — just as current medical testing allows experiments done on one set of humans (or animals) to be brought to bear in the care of other humans. It would help maintain notions of relevance, provenance and reliability, in the way that the current banking system focuses on such challenges in the domain of finance and payment. And, while one can foresee many problems arising in such a system — involving privacy issues, liability issues, security issues, etc — these problems should properly be viewed as challenges, not show-stoppers.\\nWe now come to a critical issue: Is working on classical human-imitative AI the best or only way to focus on these larger challenges? Some of the most heralded recent success stories of ML have in fact been in areas associated with human-imitative AI — areas such as computer vision, speech recognition, game-playing and robotics. So perhaps we should simply await further progress in domains such as these. There are two points to make here. First, although one would not know it from reading the newspapers, success in human-imitative AI has in fact been limited — we are very far from realizing human-imitative AI aspirations. Unfortunately the thrill (and fear) of making even limited progress on human-imitative AI gives rise to levels of over-exuberance and media attention that is not present in other areas of engineering.\\nSecond, and more importantly, success in these domains is neither sufficient nor necessary to solve important IA and II problems. On the sufficiency side, consider self-driving cars. For such technology to be realized, a range of engineering problems will need to be solved that may have little relationship to human competencies (or human lack-of-competencies). The overall transportation system (an II system) will likely more closely resemble the current air-traffic control system than the current collection of loosely-coupled, forward-facing, inattentive human drivers. It will be vastly more complex than the current air-traffic control system, specifically in its use of massive amounts of data and adaptive statistical modeling to inform fine-grained decisions. It is those challenges that need to be in the forefront, and in such an effort a focus on human-imitative AI may be a distraction.\\nAs for the necessity argument, it is sometimes argued that the human-imitative AI aspiration subsumes IA and II aspirations, because a human-imitative AI system would not only be able to solve the classical problems of AI (as embodied, e.g., in the Turing test), but it would also be our best bet for solving IA and II problems. Such an argument has little historical precedent. Did civil engineering develop by envisaging the creation of an artificial carpenter or bricklayer? Should chemical engineering have been framed in terms of creating an artificial chemist? Even more polemically: if our goal was to build chemical factories, should we have first created an artificial chemist who would have then worked out how to build a chemical factory?\\nA related argument is that human intelligence is the only kind of intelligence that we know, and that we should aim to mimic it as a first step. But humans are in fact not very good at some kinds of reasoning — we have our lapses, biases and limitations. Moreover, critically, we did not evolve to perform the kinds of large-scale decision-making that modern II systems must face, nor to cope with the kinds of uncertainty that arise in II contexts. One could argue that an AI system would not only imitate human intelligence, but also “correct” it, and would also scale to arbitrarily large problems. But we are now in the realm of science fiction — such speculative arguments, while entertaining in the setting of fiction, should not be our principal strategy going forward in the face of the critical IA and II problems that are beginning to emerge. We need to solve IA and II problems on their own merits, not as a mere corollary to a human-imitative AI agenda.\\nIt is not hard to pinpoint algorithmic and infrastructure challenges in II systems that are not central themes in human-imitative AI research. II systems require the ability to manage distributed repositories of knowledge that are rapidly changing and are likely to be globally incoherent. Such systems must cope with cloud-edge interactions in making timely, distributed decisions and they must deal with long-tail phenomena whereby there is lots of data on some individuals and little data on most individuals. They must address the difficulties of sharing data across administrative and competitive boundaries. Finally, and of particular importance, II systems must bring economic ideas such as incentives and pricing into the realm of the statistical and computational infrastructures that link humans to each other and to valued goods. Such II systems can be viewed as not merely providing a service, but as creating markets. There are domains such as music, literature and journalism that are crying out for the emergence of such markets, where data analysis links producers and consumers. And this must all be done within the context of evolving societal, ethical and legal norms.\\nOf course, classical human-imitative AI problems remain of great interest as well. However, the current focus on doing AI research via the gathering of data, the deployment of “deep learning” infrastructure, and the demonstration of systems that mimic certain narrowly-defined human skills — with little in the way of emerging explanatory principles — tends to deflect attention from major open problems in classical AI. These problems include the need to bring meaning and reasoning into systems that perform natural language processing, the need to infer and represent causality, the need to develop computationally-tractable representations of uncertainty and the need to develop systems that formulate and pursue long-term goals. These are classical goals in human-imitative AI, but in the current hubbub over the “AI revolution,” it is easy to forget that they are not yet solved.\\nIA will also remain quite essential, because for the foreseeable future, computers will not be able to match humans in their ability to reason abstractly about real-world situations. We will need well-thought-out interactions of humans and computers to solve our most pressing problems. And we will want computers to trigger new levels of human creativity, not replace human creativity (whatever that might mean).\\nIt was John McCarthy (while a professor at Dartmouth, and soon to take a position at MIT) who coined the term “AI,” apparently to distinguish his budding research agenda from that of Norbert Wiener (then an older professor at MIT). Wiener had coined “cybernetics” to refer to his own vision of intelligent systems — a vision that was closely tied to operations research, statistics, pattern recognition, information theory and control theory. McCarthy, on the other hand, emphasized the ties to logic. In an interesting reversal, it is Wiener’s intellectual agenda that has come to dominate in the current era, under the banner of McCarthy’s terminology. (This state of affairs is surely, however, only temporary; the pendulum swings more in AI than in most fields.)\\nBut we need to move beyond the particular historical perspectives of McCarthy and Wiener.\\nWe need to realize that the current public dialog on AI — which focuses on a narrow subset of industry and a narrow subset of academia — risks blinding us to the challenges and opportunities that are presented by the full scope of AI, IA and II.\\nThis scope is less about the realization of science-fiction dreams or nightmares of super-human machines, and more about the need for humans to understand and shape technology as it becomes ever more present and influential in their daily lives. Moreover, in this understanding and shaping there is a need for a diverse set of voices from all walks of life, not merely a dialog among the technologically attuned. Focusing narrowly on human-imitative AI prevents an appropriately wide range of voices from being heard.\\nWhile industry will continue to drive many developments, academia will also continue to play an essential role, not only in providing some of the most innovative technical ideas, but also in bringing researchers from the computational and statistical disciplines together with researchers from other disciplines whose contributions and perspectives are sorely needed — notably the social sciences, the cognitive sciences and the humanities.\\nOn the other hand, while the humanities and the sciences are essential as we go forward, we should also not pretend that we are talking about something other than an engineering effort of unprecedented scale and scope — society is aiming to build new kinds of artifacts. These artifacts should be built to work as claimed. We do not want to build systems that help us with medical treatments, transportation options and commercial opportunities to find out after the fact that these systems don’t really work — that they make errors that take their toll in terms of human lives and happiness. In this regard, as I have emphasized, there is an engineering discipline yet to emerge for the data-focused and learning-focused fields. As exciting as these latter fields appear to be, they cannot yet be viewed as constituting an engineering discipline.\\nMoreover, we should embrace the fact that what we are witnessing is the creation of a new branch of engineering. The term “engineering” is often invoked in a narrow sense — in academia and beyond — with overtones of cold, affectless machinery, and negative connotations of loss of control by humans. But an engineering discipline can be what we want it to be.\\nIn the current era, we have a real opportunity to conceive of something historically new — a human-centric engineering discipline.\\nI will resist giving this emerging discipline a name, but if the acronym “AI” continues to be used as placeholder nomenclature going forward, let’s be aware of the very real limitations of this placeholder. Let’s broaden our scope, tone down the hype and recognize the serious challenges ahead.\\nMichael I. Jordan\\nFrom a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\\nMichael I. Jordan is a Professor in the Department of Electrical Engineering and Computer Sciences and the Department of Statistics at UC Berkeley.\\n Artificial Intelligence (AI) is the mantra of the current era. The phrase is intoned by technologists, academicians, journalists and venture capitalists alike. As with many phrases that cross over from technical academic fields into general circulation, there is significant misunderstanding accompanying the use of the phrase. But this is not the classical case of the public not understanding the scientists — here the scientists are often as befuddled as the public. The idea that our era is somehow seeing the emergence of an intelligence in silicon that rivals our own entertains all of us — enthralling us and frightening us in equal measure. And, unfortunately, it distracts us.\\nThere is a different narrative that one can tell about the current era. Consider the following story, which involves humans, computers, data and life-or-death decisions, but where the focus is something other than intelligence-in-silicon fantasies. When my spouse was pregnant 14 years ago, we had an ultrasound. There was a geneticist in the room, and she pointed out some white spots around the heart of the fetus. “Those are markers for Down syndrome,” she noted, “and your risk has now gone up to 1 in 20.” She further let us know that we could learn whether the fetus in fact had the genetic modification underlying Down syndrome via an amniocentesis. But amniocentesis was risky — the risk of killing the fetus during the procedure was roughly 1 in 300. Being a statistician, I determined to find out where these numbers were coming from. To cut a long story short, I discovered that a statistical analysis had been done a decade previously in the UK, where these white spots, which reflect calcium buildup, were indeed established as a predictor of Down syndrome. But I also noticed that the imaging machine used in our test had a few hundred more pixels per square inch than the machine used in the UK study. I went back to tell the geneticist that I believed that the white spots were likely false positives — that they were literally “white noise.” She said “Ah, that explains why we started seeing an uptick in Down syndrome diagnoses a few years ago; it’s when the new machine arrived.”\\nWe didn’t do the amniocentesis, and a healthy girl was born a few months later. But the episode troubled me, particularly after a back-of-the-envelope calculation convinced me that many thousands of people had gotten that diagnosis that same day worldwide, that many of them had opted for amniocentesis, and that a number of babies had died needlessly. And this happened day after day until it somehow got fixed. The problem that this episode revealed wasn’t about my individual medical care; it was about a medical system that measured variables and outcomes in various places and times, conducted statistical analyses, and made use of the results in other places and times. The problem had to do not just with data analysis per se, but with what database researchers call “provenance” — broadly, where did data arise, what inferences were drawn from the data, and how relevant are those inferences to the present situation? While a trained human might be able to work all of this out on a case-by-case basis, the issue was that of designing a planetary-scale medical system that could do this without the need for such detailed human oversight.\\nI’m also a computer scientist, and it occurred to me that the principles needed to build planetary-scale inference-and-decision-making systems of this kind, blending computer science with statistics, and taking into account human utilities, were nowhere to be found in my education. And it occurred to me that the development of such principles — which will be needed not only in the medical domain but also in domains such as commerce, transportation and education — were at least as important as those of building AI systems that can dazzle us with their game-playing or sensorimotor skills.\\nWhether or not we come to understand “intelligence” any time soon, we do have a major challenge on our hands in bringing together computers and humans in ways that enhance human life. While this challenge is viewed by some as subservient to the creation of “artificial intelligence,” it can also be viewed more prosaically — but with no less reverence — as the creation of a new branch of engineering. Much like civil engineering and chemical engineering in decades past, this new discipline aims to corral the power of a few key ideas, bringing new resources and capabilities to people, and doing so safely. Whereas civil engineering and chemical engineering were built on physics and chemistry, this new engineering discipline will be built on ideas that the preceding century gave substance to — ideas such as “information,” “algorithm,” “data,” “uncertainty,” “computing,” “inference,” and “optimization.” Moreover, since much of the focus of the new discipline will be on data from and about humans, its development will require perspectives from the social sciences and humanities.\\nWhile the building blocks have begun to emerge, the principles for putting these blocks together have not yet emerged, and so the blocks are currently being put together in ad-hoc ways.\\nThus, just as humans built buildings and bridges before there was civil engineering, humans are proceeding with the building of societal-scale, inference-and-decision-making systems that involve machines, humans and the environment. Just as early buildings and bridges sometimes fell to the ground — in unforeseen ways and with tragic consequences — many of our early societal-scale inference-and-decision-making systems are already exposing serious conceptual flaws.\\nAnd, unfortunately, we are not very good at anticipating what the next emerging serious flaw will be. What we’re missing is an engineering discipline with its principles of analysis and design.\\nThe current public dialog about these issues too often uses “AI” as an intellectual wildcard, one that makes it difficult to reason about the scope and consequences of emerging technology. Let us begin by considering more carefully what “AI” has been used to refer to, both recently and historically.\\nMost of what is being called “AI” today, particularly in the public sphere, is what has been called “Machine Learning” (ML) for the past several decades. ML is an algorithmic field that blends ideas from statistics, computer science and many other disciplines (see below) to design algorithms that process data, make predictions and help make decisions. In terms of impact on the real world, ML is the real thing, and not just recently. Indeed, that ML would grow into massive industrial relevance was already clear in the early 1990s, and by the turn of the century forward-looking companies such as Amazon were already using ML throughout their business, solving mission-critical back-end problems in fraud detection and supply-chain prediction, and building innovative consumer-facing services such as recommendation systems. As datasets and computing resources grew rapidly over the ensuing two decades, it became clear that ML would soon power not only Amazon but essentially any company in which decisions could be tied to large-scale data. New business models would emerge. The phrase “Data Science” began to be used to refer to this phenomenon, reflecting the need of ML algorithms experts to partner with database and distributed-systems experts to build scalable, robust ML systems, and reflecting the larger social and environmental scope of the resulting systems.\\nThis confluence of ideas and technology trends has been rebranded as “AI” over the past few years. This rebranding is worthy of some scrutiny.\\nHistorically, the phrase “AI” was coined in the late 1950’s to refer to the heady aspiration of realizing in software and hardware an entity possessing human-level intelligence. We will use the phrase “human-imitative AI” to refer to this aspiration, emphasizing the notion that the artificially intelligent entity should seem to be one of us, if not physically at least mentally (whatever that might mean). This was largely an academic enterprise. While related academic fields such as operations research, statistics, pattern recognition, information theory and control theory already existed, and were often inspired by human intelligence (and animal intelligence), these fields were arguably focused on “low-level” signals and decisions. The ability of, say, a squirrel to perceive the three-dimensional structure of the forest it lives in, and to leap among its branches, was inspirational to these fields. “AI” was meant to focus on something different — the “high-level” or “cognitive” capability of humans to “reason” and to “think.” Sixty years later, however, high-level reasoning and thought remain elusive. The developments which are now being called “AI” arose mostly in the engineering fields associated with low-level pattern recognition and movement control, and in the field of statistics — the discipline focused on finding patterns in data and on making well-founded predictions, tests of hypotheses and decisions.\\nIndeed, the famous “backpropagation” algorithm that was rediscovered by David Rumelhart in the early 1980s, and which is now viewed as being at the core of the so-called “AI revolution,” first arose in the field of control theory in the 1950s and 1960s. One of its early applications was to optimize the thrusts of the Apollo spaceships as they headed towards the moon.\\nSince the 1960s much progress has been made, but it has arguably not come about from the pursuit of human-imitative AI. Rather, as in the case of the Apollo spaceships, these ideas have often been hidden behind the scenes, and have been the handiwork of researchers focused on specific engineering challenges. Although not visible to the general public, research and systems-building in areas such as document retrieval, text classification, fraud detection, recommendation systems, personalized search, social network analysis, planning, diagnostics and A/B testing have been a major success — these are the advances that have powered companies such as Google, Netflix, Facebook and Amazon.\\nOne could simply agree to refer to all of this as “AI,” and indeed that is what appears to have happened. Such labeling may come as a surprise to optimization or statistics researchers, who wake up to find themselves suddenly referred to as “AI researchers.” But labeling of researchers aside, the bigger problem is that the use of this single, ill-defined acronym prevents a clear understanding of the range of intellectual and commercial issues at play.\\nThe past two decades have seen major progress — in industry and academia — in a complementary aspiration to human-imitative AI that is often referred to as “Intelligence Augmentation” (IA). Here computation and data are used to create services that augment human intelligence and creativity. A search engine can be viewed as an example of IA (it augments human memory and factual knowledge), as can natural language translation (it augments the ability of a human to communicate). Computing-based generation of sounds and images serves as a palette and creativity enhancer for artists. While services of this kind could conceivably involve high-level reasoning and thought, currently they don’t — they mostly perform various kinds of string-matching and numerical operations that capture patterns that humans can make use of.\\nHoping that the reader will tolerate one last acronym, let us conceive broadly of a discipline of “Intelligent Infrastructure” (II), whereby a web of computation, data and physical entities exists that makes human environments more supportive, interesting and safe. Such infrastructure is beginning to make its appearance in domains such as transportation, medicine, commerce and finance, with vast implications for individual humans and societies. This emergence sometimes arises in conversations about an “Internet of Things,” but that effort generally refers to the mere problem of getting “things” onto the Internet — not to the far grander set of challenges associated with these “things” capable of analyzing those data streams to discover facts about the world, and interacting with humans and other “things” at a far higher level of abstraction than mere bits.\\nFor example, returning to my personal anecdote, we might imagine living our lives in a “societal-scale medical system” that sets up data flows, and data-analysis flows, between doctors and devices positioned in and around human bodies, thereby able to aid human intelligence in making diagnoses and providing care. The system would incorporate information from cells in the body, DNA, blood tests, environment, population genetics and the vast scientific literature on drugs and treatments. It would not just focus on a single patient and a doctor, but on relationships among all humans — just as current medical testing allows experiments done on one set of humans (or animals) to be brought to bear in the care of other humans. It would help maintain notions of relevance, provenance and reliability, in the way that the current banking system focuses on such challenges in the domain of finance and payment. And, while one can foresee many problems arising in such a system — involving privacy issues, liability issues, security issues, etc — these problems should properly be viewed as challenges, not show-stoppers.\\nWe now come to a critical issue: Is working on classical human-imitative AI the best or only way to focus on these larger challenges? Some of the most heralded recent success stories of ML have in fact been in areas associated with human-imitative AI — areas such as computer vision, speech recognition, game-playing and robotics. So perhaps we should simply await further progress in domains such as these. There are two points to make here. First, although one would not know it from reading the newspapers, success in human-imitative AI has in fact been limited — we are very far from realizing human-imitative AI aspirations. Unfortunately the thrill (and fear) of making even limited progress on human-imitative AI gives rise to levels of over-exuberance and media attention that is not present in other areas of engineering.\\nSecond, and more importantly, success in these domains is neither sufficient nor necessary to solve important IA and II problems. On the sufficiency side, consider self-driving cars. For such technology to be realized, a range of engineering problems will need to be solved that may have little relationship to human competencies (or human lack-of-competencies). The overall transportation system (an II system) will likely more closely resemble the current air-traffic control system than the current collection of loosely-coupled, forward-facing, inattentive human drivers. It will be vastly more complex than the current air-traffic control system, specifically in its use of massive amounts of data and adaptive statistical modeling to inform fine-grained decisions. It is those challenges that need to be in the forefront, and in such an effort a focus on human-imitative AI may be a distraction.\\nAs for the necessity argument, it is sometimes argued that the human-imitative AI aspiration subsumes IA and II aspirations, because a human-imitative AI system would not only be able to solve the classical problems of AI (as embodied, e.g., in the Turing test), but it would also be our best bet for solving IA and II problems. Such an argument has little historical precedent. Did civil engineering develop by envisaging the creation of an artificial carpenter or bricklayer? Should chemical engineering have been framed in terms of creating an artificial chemist? Even more polemically: if our goal was to build chemical factories, should we have first created an artificial chemist who would have then worked out how to build a chemical factory?\\nA related argument is that human intelligence is the only kind of intelligence that we know, and that we should aim to mimic it as a first step. But humans are in fact not very good at some kinds of reasoning — we have our lapses, biases and limitations. Moreover, critically, we did not evolve to perform the kinds of large-scale decision-making that modern II systems must face, nor to cope with the kinds of uncertainty that arise in II contexts. One could argue that an AI system would not only imitate human intelligence, but also “correct” it, and would also scale to arbitrarily large problems. But we are now in the realm of science fiction — such speculative arguments, while entertaining in the setting of fiction, should not be our principal strategy going forward in the face of the critical IA and II problems that are beginning to emerge. We need to solve IA and II problems on their own merits, not as a mere corollary to a human-imitative AI agenda.\\nIt is not hard to pinpoint algorithmic and infrastructure challenges in II systems that are not central themes in human-imitative AI research. II systems require the ability to manage distributed repositories of knowledge that are rapidly changing and are likely to be globally incoherent. Such systems must cope with cloud-edge interactions in making timely, distributed decisions and they must deal with long-tail phenomena whereby there is lots of data on some individuals and little data on most individuals. They must address the difficulties of sharing data across administrative and competitive boundaries. Finally, and of particular importance, II systems must bring economic ideas such as incentives and pricing into the realm of the statistical and computational infrastructures that link humans to each other and to valued goods. Such II systems can be viewed as not merely providing a service, but as creating markets. There are domains such as music, literature and journalism that are crying out for the emergence of such markets, where data analysis links producers and consumers. And this must all be done within the context of evolving societal, ethical and legal norms.\\nOf course, classical human-imitative AI problems remain of great interest as well. However, the current focus on doing AI research via the gathering of data, the deployment of “deep learning” infrastructure, and the demonstration of systems that mimic certain narrowly-defined human skills — with little in the way of emerging explanatory principles — tends to deflect attention from major open problems in classical AI. These problems include the need to bring meaning and reasoning into systems that perform natural language processing, the need to infer and represent causality, the need to develop computationally-tractable representations of uncertainty and the need to develop systems that formulate and pursue long-term goals. These are classical goals in human-imitative AI, but in the current hubbub over the “AI revolution,” it is easy to forget that they are not yet solved.\\nIA will also remain quite essential, because for the foreseeable future, computers will not be able to match humans in their ability to reason abstractly about real-world situations. We will need well-thought-out interactions of humans and computers to solve our most pressing problems. And we will want computers to trigger new levels of human creativity, not replace human creativity (whatever that might mean).\\nIt was John McCarthy (while a professor at Dartmouth, and soon to take a position at MIT) who coined the term “AI,” apparently to distinguish his budding research agenda from that of Norbert Wiener (then an older professor at MIT). Wiener had coined “cybernetics” to refer to his own vision of intelligent systems — a vision that was closely tied to operations research, statistics, pattern recognition, information theory and control theory. McCarthy, on the other hand, emphasized the ties to logic. In an interesting reversal, it is Wiener’s intellectual agenda that has come to dominate in the current era, under the banner of McCarthy’s terminology. (This state of affairs is surely, however, only temporary; the pendulum swings more in AI than in most fields.)\\nBut we need to move beyond the particular historical perspectives of McCarthy and Wiener.\\nWe need to realize that the current public dialog on AI — which focuses on a narrow subset of industry and a narrow subset of academia — risks blinding us to the challenges and opportunities that are presented by the full scope of AI, IA and II.\\nThis scope is less about the realization of science-fiction dreams or nightmares of super-human machines, and more about the need for humans to understand and shape technology as it becomes ever more present and influential in their daily lives. Moreover, in this understanding and shaping there is a need for a diverse set of voices from all walks of life, not merely a dialog among the technologically attuned. Focusing narrowly on human-imitative AI prevents an appropriately wide range of voices from being heard.\\nWhile industry will continue to drive many developments, academia will also continue to play an essential role, not only in providing some of the most innovative technical ideas, but also in bringing researchers from the computational and statistical disciplines together with researchers from other disciplines whose contributions and perspectives are sorely needed — notably the social sciences, the cognitive sciences and the humanities.\\nOn the other hand, while the humanities and the sciences are essential as we go forward, we should also not pretend that we are talking about something other than an engineering effort of unprecedented scale and scope — society is aiming to build new kinds of artifacts. These artifacts should be built to work as claimed. We do not want to build systems that help us with medical treatments, transportation options and commercial opportunities to find out after the fact that these systems don’t really work — that they make errors that take their toll in terms of human lives and happiness. In this regard, as I have emphasized, there is an engineering discipline yet to emerge for the data-focused and learning-focused fields. As exciting as these latter fields appear to be, they cannot yet be viewed as constituting an engineering discipline.\\nMoreover, we should embrace the fact that what we are witnessing is the creation of a new branch of engineering. The term “engineering” is often invoked in a narrow sense — in academia and beyond — with overtones of cold, affectless machinery, and negative connotations of loss of control by humans. But an engineering discipline can be what we want it to be.\\nIn the current era, we have a real opportunity to conceive of something historically new — a human-centric engineering discipline.\\nI will resist giving this emerging discipline a name, but if the acronym “AI” continues to be used as placeholder nomenclature going forward, let’s be aware of the very real limitations of this placeholder. Let’s broaden our scope, tone down the hype and recognize the serious challenges ahead.\\nMichael I. Jordan\\nFrom a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\\nMichael I. Jordan is a Professor in the Department of Electrical Engineering and Computer Sciences and the Department of Statistics at UC Berkeley.\\n Artificial Intelligence (AI) is the mantra of the current era. The phrase is intoned by technologists, academicians, journalists and venture capitalists alike. As with many phrases that cross over from technical academic fields into general circulation, there is significant misunderstanding accompanying the use of the phrase. But this is not the classical case of the public not understanding the scientists — here the scientists are often as befuddled as the public. The idea that our era is somehow seeing the emergence of an intelligence in silicon that rivals our own entertains all of us — enthralling us and frightening us in equal measure. And, unfortunately, it distracts us.\\nThere is a different narrative that one can tell about the current era. Consider the following story, which involves humans, computers, data and life-or-death decisions, but where the focus is something other than intelligence-in-silicon fantasies. When my spouse was pregnant 14 years ago, we had an ultrasound. There was a geneticist in the room, and she pointed out some white spots around the heart of the fetus. “Those are markers for Down syndrome,” she noted, “and your risk has now gone up to 1 in 20.” She further let us know that we could learn whether the fetus in fact had the genetic modification underlying Down syndrome via an amniocentesis. But amniocentesis was risky — the risk of killing the fetus during the procedure was roughly 1 in 300. Being a statistician, I determined to find out where these numbers were coming from. To cut a long story short, I discovered that a statistical analysis had been done a decade previously in the UK, where these white spots, which reflect calcium buildup, were indeed established as a predictor of Down syndrome. But I also noticed that the imaging machine used in our test had a few hundred more pixels per square inch than the machine used in the UK study. I went back to tell the geneticist that I believed that the white spots were likely false positives — that they were literally “white noise.” She said “Ah, that explains why we started seeing an uptick in Down syndrome diagnoses a few years ago; it’s when the new machine arrived.”\\nWe didn’t do the amniocentesis, and a healthy girl was born a few months later. But the episode troubled me, particularly after a back-of-the-envelope calculation convinced me that many thousands of people had gotten that diagnosis that same day worldwide, that many of them had opted for amniocentesis, and that a number of babies had died needlessly. And this happened day after day until it somehow got fixed. The problem that this episode revealed wasn’t about my individual medical care; it was about a medical system that measured variables and outcomes in various places and times, conducted statistical analyses, and made use of the results in other places and times. The problem had to do not just with data analysis per se, but with what database researchers call “provenance” — broadly, where did data arise, what inferences were drawn from the data, and how relevant are those inferences to the present situation? While a trained human might be able to work all of this out on a case-by-case basis, the issue was that of designing a planetary-scale medical system that could do this without the need for such detailed human oversight.\\nI’m also a computer scientist, and it occurred to me that the principles needed to build planetary-scale inference-and-decision-making systems of this kind, blending computer science with statistics, and taking into account human utilities, were nowhere to be found in my education. And it occurred to me that the development of such principles — which will be needed not only in the medical domain but also in domains such as commerce, transportation and education — were at least as important as those of building AI systems that can dazzle us with their game-playing or sensorimotor skills.\\nWhether or not we come to understand “intelligence” any time soon, we do have a major challenge on our hands in bringing together computers and humans in ways that enhance human life. While this challenge is viewed by some as subservient to the creation of “artificial intelligence,” it can also be viewed more prosaically — but with no less reverence — as the creation of a new branch of engineering. Much like civil engineering and chemical engineering in decades past, this new discipline aims to corral the power of a few key ideas, bringing new resources and capabilities to people, and doing so safely. Whereas civil engineering and chemical engineering were built on physics and chemistry, this new engineering discipline will be built on ideas that the preceding century gave substance to — ideas such as “information,” “algorithm,” “data,” “uncertainty,” “computing,” “inference,” and “optimization.” Moreover, since much of the focus of the new discipline will be on data from and about humans, its development will require perspectives from the social sciences and humanities.\\nWhile the building blocks have begun to emerge, the principles for putting these blocks together have not yet emerged, and so the blocks are currently being put together in ad-hoc ways.\\nThus, just as humans built buildings and bridges before there was civil engineering, humans are proceeding with the building of societal-scale, inference-and-decision-making systems that involve machines, humans and the environment. Just as early buildings and bridges sometimes fell to the ground — in unforeseen ways and with tragic consequences — many of our early societal-scale inference-and-decision-making systems are already exposing serious conceptual flaws.\\nAnd, unfortunately, we are not very good at anticipating what the next emerging serious flaw will be. What we’re missing is an engineering discipline with its principles of analysis and design.\\nThe current public dialog about these issues too often uses “AI” as an intellectual wildcard, one that makes it difficult to reason about the scope and consequences of emerging technology. Let us begin by considering more carefully what “AI” has been used to refer to, both recently and historically.\\nMost of what is being called “AI” today, particularly in the public sphere, is what has been called “Machine Learning” (ML) for the past several decades. ML is an algorithmic field that blends ideas from statistics, computer science and many other disciplines (see below) to design algorithms that process data, make predictions and help make decisions. In terms of impact on the real world, ML is the real thing, and not just recently. Indeed, that ML would grow into massive industrial relevance was already clear in the early 1990s, and by the turn of the century forward-looking companies such as Amazon were already using ML throughout their business, solving mission-critical back-end problems in fraud detection and supply-chain prediction, and building innovative consumer-facing services such as recommendation systems. As datasets and computing resources grew rapidly over the ensuing two decades, it became clear that ML would soon power not only Amazon but essentially any company in which decisions could be tied to large-scale data. New business models would emerge. The phrase “Data Science” began to be used to refer to this phenomenon, reflecting the need of ML algorithms experts to partner with database and distributed-systems experts to build scalable, robust ML systems, and reflecting the larger social and environmental scope of the resulting systems.\\nThis confluence of ideas and technology trends has been rebranded as “AI” over the past few years. This rebranding is worthy of some scrutiny.\\nHistorically, the phrase “AI” was coined in the late 1950’s to refer to the heady aspiration of realizing in software and hardware an entity possessing human-level intelligence. We will use the phrase “human-imitative AI” to refer to this aspiration, emphasizing the notion that the artificially intelligent entity should seem to be one of us, if not physically at least mentally (whatever that might mean). This was largely an academic enterprise. While related academic fields such as operations research, statistics, pattern recognition, information theory and control theory already existed, and were often inspired by human intelligence (and animal intelligence), these fields were arguably focused on “low-level” signals and decisions. The ability of, say, a squirrel to perceive the three-dimensional structure of the forest it lives in, and to leap among its branches, was inspirational to these fields. “AI” was meant to focus on something different — the “high-level” or “cognitive” capability of humans to “reason” and to “think.” Sixty years later, however, high-level reasoning and thought remain elusive. The developments which are now being called “AI” arose mostly in the engineering fields associated with low-level pattern recognition and movement control, and in the field of statistics — the discipline focused on finding patterns in data and on making well-founded predictions, tests of hypotheses and decisions.\\nIndeed, the famous “backpropagation” algorithm that was rediscovered by David Rumelhart in the early 1980s, and which is now viewed as being at the core of the so-called “AI revolution,” first arose in the field of control theory in the 1950s and 1960s. One of its early applications was to optimize the thrusts of the Apollo spaceships as they headed towards the moon.\\nSince the 1960s much progress has been made, but it has arguably not come about from the pursuit of human-imitative AI. Rather, as in the case of the Apollo spaceships, these ideas have often been hidden behind the scenes, and have been the handiwork of researchers focused on specific engineering challenges. Although not visible to the general public, research and systems-building in areas such as document retrieval, text classification, fraud detection, recommendation systems, personalized search, social network analysis, planning, diagnostics and A/B testing have been a major success — these are the advances that have powered companies such as Google, Netflix, Facebook and Amazon.\\nOne could simply agree to refer to all of this as “AI,” and indeed that is what appears to have happened. Such labeling may come as a surprise to optimization or statistics researchers, who wake up to find themselves suddenly referred to as “AI researchers.” But labeling of researchers aside, the bigger problem is that the use of this single, ill-defined acronym prevents a clear understanding of the range of intellectual and commercial issues at play.\\nThe past two decades have seen major progress — in industry and academia — in a complementary aspiration to human-imitative AI that is often referred to as “Intelligence Augmentation” (IA). Here computation and data are used to create services that augment human intelligence and creativity. A search engine can be viewed as an example of IA (it augments human memory and factual knowledge), as can natural language translation (it augments the ability of a human to communicate). Computing-based generation of sounds and images serves as a palette and creativity enhancer for artists. While services of this kind could conceivably involve high-level reasoning and thought, currently they don’t — they mostly perform various kinds of string-matching and numerical operations that capture patterns that humans can make use of.\\nHoping that the reader will tolerate one last acronym, let us conceive broadly of a discipline of “Intelligent Infrastructure” (II), whereby a web of computation, data and physical entities exists that makes human environments more supportive, interesting and safe. Such infrastructure is beginning to make its appearance in domains such as transportation, medicine, commerce and finance, with vast implications for individual humans and societies. This emergence sometimes arises in conversations about an “Internet of Things,” but that effort generally refers to the mere problem of getting “things” onto the Internet — not to the far grander set of challenges associated with these “things” capable of analyzing those data streams to discover facts about the world, and interacting with humans and other “things” at a far higher level of abstraction than mere bits.\\nFor example, returning to my personal anecdote, we might imagine living our lives in a “societal-scale medical system” that sets up data flows, and data-analysis flows, between doctors and devices positioned in and around human bodies, thereby able to aid human intelligence in making diagnoses and providing care. The system would incorporate information from cells in the body, DNA, blood tests, environment, population genetics and the vast scientific literature on drugs and treatments. It would not just focus on a single patient and a doctor, but on relationships among all humans — just as current medical testing allows experiments done on one set of humans (or animals) to be brought to bear in the care of other humans. It would help maintain notions of relevance, provenance and reliability, in the way that the current banking system focuses on such challenges in the domain of finance and payment. And, while one can foresee many problems arising in such a system — involving privacy issues, liability issues, security issues, etc — these problems should properly be viewed as challenges, not show-stoppers.\\nWe now come to a critical issue: Is working on classical human-imitative AI the best or only way to focus on these larger challenges? Some of the most heralded recent success stories of ML have in fact been in areas associated with human-imitative AI — areas such as computer vision, speech recognition, game-playing and robotics. So perhaps we should simply await further progress in domains such as these. There are two points to make here. First, although one would not know it from reading the newspapers, success in human-imitative AI has in fact been limited — we are very far from realizing human-imitative AI aspirations. Unfortunately the thrill (and fear) of making even limited progress on human-imitative AI gives rise to levels of over-exuberance and media attention that is not present in other areas of engineering.\\nSecond, and more importantly, success in these domains is neither sufficient nor necessary to solve important IA and II problems. On the sufficiency side, consider self-driving cars. For such technology to be realized, a range of engineering problems will need to be solved that may have little relationship to human competencies (or human lack-of-competencies). The overall transportation system (an II system) will likely more closely resemble the current air-traffic control system than the current collection of loosely-coupled, forward-facing, inattentive human drivers. It will be vastly more complex than the current air-traffic control system, specifically in its use of massive amounts of data and adaptive statistical modeling to inform fine-grained decisions. It is those challenges that need to be in the forefront, and in such an effort a focus on human-imitative AI may be a distraction.\\nAs for the necessity argument, it is sometimes argued that the human-imitative AI aspiration subsumes IA and II aspirations, because a human-imitative AI system would not only be able to solve the classical problems of AI (as embodied, e.g., in the Turing test), but it would also be our best bet for solving IA and II problems. Such an argument has little historical precedent. Did civil engineering develop by envisaging the creation of an artificial carpenter or bricklayer? Should chemical engineering have been framed in terms of creating an artificial chemist? Even more polemically: if our goal was to build chemical factories, should we have first created an artificial chemist who would have then worked out how to build a chemical factory?\\nA related argument is that human intelligence is the only kind of intelligence that we know, and that we should aim to mimic it as a first step. But humans are in fact not very good at some kinds of reasoning — we have our lapses, biases and limitations. Moreover, critically, we did not evolve to perform the kinds of large-scale decision-making that modern II systems must face, nor to cope with the kinds of uncertainty that arise in II contexts. One could argue that an AI system would not only imitate human intelligence, but also “correct” it, and would also scale to arbitrarily large problems. But we are now in the realm of science fiction — such speculative arguments, while entertaining in the setting of fiction, should not be our principal strategy going forward in the face of the critical IA and II problems that are beginning to emerge. We need to solve IA and II problems on their own merits, not as a mere corollary to a human-imitative AI agenda.\\nIt is not hard to pinpoint algorithmic and infrastructure challenges in II systems that are not central themes in human-imitative AI research. II systems require the ability to manage distributed repositories of knowledge that are rapidly changing and are likely to be globally incoherent. Such systems must cope with cloud-edge interactions in making timely, distributed decisions and they must deal with long-tail phenomena whereby there is lots of data on some individuals and little data on most individuals. They must address the difficulties of sharing data across administrative and competitive boundaries. Finally, and of particular importance, II systems must bring economic ideas such as incentives and pricing into the realm of the statistical and computational infrastructures that link humans to each other and to valued goods. Such II systems can be viewed as not merely providing a service, but as creating markets. There are domains such as music, literature and journalism that are crying out for the emergence of such markets, where data analysis links producers and consumers. And this must all be done within the context of evolving societal, ethical and legal norms.\\nOf course, classical human-imitative AI problems remain of great interest as well. However, the current focus on doing AI research via the gathering of data, the deployment of “deep learning” infrastructure, and the demonstration of systems that mimic certain narrowly-defined human skills — with little in the way of emerging explanatory principles — tends to deflect attention from major open problems in classical AI. These problems include the need to bring meaning and reasoning into systems that perform natural language processing, the need to infer and represent causality, the need to develop computationally-tractable representations of uncertainty and the need to develop systems that formulate and pursue long-term goals. These are classical goals in human-imitative AI, but in the current hubbub over the “AI revolution,” it is easy to forget that they are not yet solved.\\nIA will also remain quite essential, because for the foreseeable future, computers will not be able to match humans in their ability to reason abstractly about real-world situations. We will need well-thought-out interactions of humans and computers to solve our most pressing problems. And we will want computers to trigger new levels of human creativity, not replace human creativity (whatever that might mean).\\nIt was John McCarthy (while a professor at Dartmouth, and soon to take a position at MIT) who coined the term “AI,” apparently to distinguish his budding research agenda from that of Norbert Wiener (then an older professor at MIT). Wiener had coined “cybernetics” to refer to his own vision of intelligent systems — a vision that was closely tied to operations research, statistics, pattern recognition, information theory and control theory. McCarthy, on the other hand, emphasized the ties to logic. In an interesting reversal, it is Wiener’s intellectual agenda that has come to dominate in the current era, under the banner of McCarthy’s terminology. (This state of affairs is surely, however, only temporary; the pendulum swings more in AI than in most fields.)\\nBut we need to move beyond the particular historical perspectives of McCarthy and Wiener.\\nWe need to realize that the current public dialog on AI — which focuses on a narrow subset of industry and a narrow subset of academia — risks blinding us to the challenges and opportunities that are presented by the full scope of AI, IA and II.\\nThis scope is less about the realization of science-fiction dreams or nightmares of super-human machines, and more about the need for humans to understand and shape technology as it becomes ever more present and influential in their daily lives. Moreover, in this understanding and shaping there is a need for a diverse set of voices from all walks of life, not merely a dialog among the technologically attuned. Focusing narrowly on human-imitative AI prevents an appropriately wide range of voices from being heard.\\nWhile industry will continue to drive many developments, academia will also continue to play an essential role, not only in providing some of the most innovative technical ideas, but also in bringing researchers from the computational and statistical disciplines together with researchers from other disciplines whose contributions and perspectives are sorely needed — notably the social sciences, the cognitive sciences and the humanities.\\nOn the other hand, while the humanities and the sciences are essential as we go forward, we should also not pretend that we are talking about something other than an engineering effort of unprecedented scale and scope — society is aiming to build new kinds of artifacts. These artifacts should be built to work as claimed. We do not want to build systems that help us with medical treatments, transportation options and commercial opportunities to find out after the fact that these systems don’t really work — that they make errors that take their toll in terms of human lives and happiness. In this regard, as I have emphasized, there is an engineering discipline yet to emerge for the data-focused and learning-focused fields. As exciting as these latter fields appear to be, they cannot yet be viewed as constituting an engineering discipline.\\nMoreover, we should embrace the fact that what we are witnessing is the creation of a new branch of engineering. The term “engineering” is often invoked in a narrow sense — in academia and beyond — with overtones of cold, affectless machinery, and negative connotations of loss of control by humans. But an engineering discipline can be what we want it to be.\\nIn the current era, we have a real opportunity to conceive of something historically new — a human-centric engineering discipline.\\nI will resist giving this emerging discipline a name, but if the acronym “AI” continues to be used as placeholder nomenclature going forward, let’s be aware of the very real limitations of this placeholder. Let’s broaden our scope, tone down the hype and recognize the serious challenges ahead.\\nMichael I. Jordan\\nFrom a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\\nMichael I. Jordan is a Professor in the Department of Electrical Engineering and Computer Sciences and the Department of Statistics at UC Berkeley.\\n The internet swarms with intelligent assistants.\\nWhat started as an isolated app on the iPhone has evolved. Intelligent assistants constitute an entirely new network of activity. No longer confined to our personal computing devices, assistants are being embedded within every object of interest in the cloud and the internet of things.\\nAssistants have become far more nimble and lightweight than their monolithic ancestors; much more like smart ants than people. As specialists, they work cooperatively — sometimes competitively — to find information before people even realize they need it.\\nPeople are still communicating directly with assistants, although rarely using natural language. Implicit communication dominates. Assistants respond and react to our subtle contextual interactions, and to each other, within vast informational ecosystems.\\nThis is how intelligent assistants evolved...\\nIntelligent assistants like Siri, Google Now, and Cortana are so young, it’s difficult to imagine how they will change; harder still to imagine how they might die. But if history is a guide, inevitably they will give way to entirely new product forms.\\nWhen pundits and analysts discuss the future of intelligent assistants, they typically extrapolate from the conceptual model of today’s assistants. The next version is always a better, smarter, faster version of the last, but it’s still the same species.\\nAs detailed in Bianca Bosker’s Inside Story of Siri’s Origins, when Apple acquired Siri, the scope of the product’s capabilities actually narrowed. Using the audacious vision of Siri’s founders as a palette, Apple selected a narrower set of product values on which to focus.\\nThe same force that reduced the scope of Apple’s Siri from a “do (everything) engine” to a much more narrow product is what keeps incumbents rooted to the existing concept of intelligent assistants.\\nWhen forecasting change, it’s not so much what the technology of intelligent assistants might support as what product leaders choose to pursue. While many brazenly contest existing markets, product leaders look for new, underserved areas of the landscape to exploit.\\nThe future always surprises, but we can predict the trajectory of change by examining which product values are being embraced, and which ones are neglected.\\nJust like directions on a compass, the following maps point to fertile areas of the landscape, where new product forms may evolve.\\nNote that product values are often coupled due to technological constraints. Decisions along one axis constrain possibilities along another. These couplings are explored at a high level in two-dimensional perceptual maps: interface and distribution; knowledge and tasks; organization and autonomy.\\nThe aspects of assistants that are most obvious to end-users are the interfaces (how we interact with assistants) and their mode of distribution (where people experience assistants).\\nToday’s assistants are overwhelmingly focused on natural language interfaces. The experience of assistants that speak our language and communicate like a person has come to define the product class.\\nThis focus on natural language interfaces has biased the distribution of assistants to personal computing devices. Intelligent assistants embody any device capable of receiving and synthesizing speech, such as smartphones, desktops, wearables and cars.\\nThe underserved areas of this map involve communications that are not based in natural language. For example, there’s much to learn about our needs and intentions based on context (where we are and what we’re doing) as well as on our ability to make inferences based on the associations that people form (for example, the way that people organize information or express their likes and dislikes). Natural language is but the tip of this much larger iceberg of communications.\\nThese alternative forms of communication not only support individuals, but also groups. While it’s difficult to understand a room full of people all speaking at once, it’s much easier to understand their collaborative communications, such as their documents, click-paths, and sharing behavior. Therefore, the options for distributing intelligent assistants that use these implicit forms of communications are not constrained to personal computing devices, but may leverage entire networks.\\nAs a simple example, consider how you highlight your interests as you browse a website. You focus your attention on specific pages within the site. You follow your interests as you navigate from page to page. You may choose to share some information within the site with a friend. Now compound this behaviour across every visitor to the site.\\nIntelligent assistants that are associated with the website can respond to these interactions to help the right information find each individual, as well as adapt the website to better address the needs of the entire group.\\nIntelligent assistants require domain knowledge to perform their tasks. For example, if your assistant is giving you advice on how to navigate to work, it needs to have knowledge about the geographic region (general knowledge) and knowledge of how you typically navigate (specific knowledge).\\nTasks and knowledge are tightly coupled. As you increase the specificity or the personalization of the tasks, the underlying knowledge needs to be far more specific to support it.\\nWithin this frame, today’s intelligent assistants are unabashedly generalists. They’re targeted to the masses. Like trivia buffs, their knowledge of the world is broad enough to be relevant to the needs of large groups of people, but few would describe them as experts. Their tasks are similarly general: retrieving information, providing navigational assistance, and answering simple questions.\\nThe underserved landscape points to much more specific domains of knowledge, the purview of experts and our individual subjective knowledge. Assistants that become experts necessarily take on a smaller scope of activities. They can’t know and do everything, so they become smaller in scope.\\nThe landscape for specific tasks is similarly underserved. Every website, every service, every app, and across the internet of things, everything embodies a collection of tasks that may be supported by intelligent assistants. In this environment, the metaphor of personal assistants quickly fragments into systems that are much more akin to colonies of ants.\\nThe organizational structures in which assistants are placed constrain their autonomy. When embedded within a personal computing device, an intelligent assistant is directed to one-to-one interactions with their master.\\nSince these assistants are acting as an agent of the individual (and only that individual), their autonomy is necessarily limited. While you might be comfortable with your executive assistant drafting your messages, I suspect you’d be less comfortable with your smartphone doing the same.\\nIn stark contrast, the underserved landscape embraces groups, both in terms of the interactions and the organizational structures.\\nAs assistants get smaller and more specialized, they can become agents of much more specific objects of interest, like places, websites, applications, and services. Within these smaller realms of interest, their autonomy can be much more expansive. You might not want a machine to act as your representative, but you would probably feel more comfortable if it represented only the website you’re visiting.\\nWith increased autonomy, the barriers to many-to-many interactions are removed. These small assistants can be organized as teams into networks, much like the documents that comprise a website, collaborating in an unfettered way with other assistants and the people that visit their realms.\\nThis market analysis highlighted a number of underserved areas as fertile ground for the evolution of intelligent assistants. It grounds this vision in predictable market dynamics. There’s obviously no shortage of space or product values to explore in these underserved areas.\\nIt says nothing, however, about when this future will arrive. Product evolution, like biological evolution, needs time and resources. The most important resource is the dedication of product leaders with the drive to pursue these new opportunities.\\nAre you an entrepreneur, technologist, or investor that’s changing the market for intelligent assistants? If so, I’d love to hear your vision of the future.\\nFrom a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\\nEntrepreneur and inventor. Interested in startups, AI or healthcare? Let's connect! https://www.linkedin.com/in/peterjsweeney/\\nEssays and analysis of artificial intelligence, machine learning, and intelligent assistants.\\n Artificial Intelligence is a state-of-the-art technological trend that many companies are trying to integrate into their business. A recent report by McKinsey states that Baidu, the Chinese equivalent of Alphabet, invested $20 billion in AI last year. At the same time, Alphabet invested roughly $30 billion in developing AI technologies. The Chinese government has been actively pursuing AI technology in an attempt to control a future cornerstone innovation. Companies in the US are also investing time, money and energy into advancing AI technology.\\nThe reason for such interest towards artificial intelligence is that artificial intelligence can enhance any product or function. This is why companies and governments make considerable investments in the research and development of this technology. Its role in increasing the production performance while simultaneously reducing the costs cannot be underestimated.\\nSince some of the largest entities in the world are focused on promoting the AI technology, it would be wise to understand and follow the trend. AI is already shaping the economy, and in the near future, its effect may be even more significant. Ignoring the new technology and its influence on the global economic situation is a recipe for failure.\\nDespite the huge public interest and attention towards AI, its evolution is still somewhat halted by the objective causes. As any new and fast-developing industry, AI is quickly outgrowing its environment. According to Adam Temper, an author of many creative researches on artificial intelligence, the development of AI is mostly limited by the “lack of employees with relevant expertise, very few mature standard industry tools, limited high quality training material available, few options for easy access to preconfigured machine learning environments, and the general focus in the industry on implementation rather than design”.\\nWith any new complex technology, the learning curve is steep. Our educational institutions are several steps behind the commercial applications of this technology. It is important that AI scientists work collaboratively, sharing knowledge and best practice, to address this deficiency. AI is rapidly increasing its impact on society; we need to ensure that the power of AI doesn’t remain with the elite few.\\nAnother factor that may be hindering the progress of AI is the cautious stance that people tend to take towards it. Artificial intelligence is still too sci-fi, too strange and, therefore, sometimes scary. When people learn to trust AI, it will make a true quantum leap in the way of general adoption and application. Adam Temper supports this point, too, describing the possible ways for AI technology to gain public trust as\\nAt the same time, if we analyze the primary purpose of AI, we will see it for what it really is — a tool to perform the routine tasks relieving humans for something more creative or innovative. When asked about the current trends and opportunities of AI, Aaron Edell, CEO and co-founder of Machine Box, and one of the top writers on AI, described them as follows:\\nAI has also become a political talking point in recent years. There have been arguments that AI will help to create jobs, but that it will also cause certain workers to lose their jobs. For example, estimations prove that self-driving vehicles will cause 25,000 truck drivers to lose their jobs each month. Also, as much as 1 million pickers and packers working in US warehouses could be out of a job. This is due to the fact that by implementing AI, factories can operate with as few as a dozen of workers.\\nNaturally, companies gladly implement artificial intelligence, as it ensures considerable savings. At the same time, governments are concerned about the current employment situation as well as the short-term and long-term predictions. Some countries have already begun to plan measures about the new AI technology that are intended to keep the economy stable.\\nIn fact, it would not be fair to say that artificial intelligence causes people to lose jobs. True, the whole point of automation is making machines do what people used to do before. However, it would be more correct if we said that artificial intelligence reshapes the employment situation. Together with taking over human functions, it creates other jobs, forces people to master new skills, encourages workers to increase productivity. But it is obvious that AI is going to turn the regular sequence of events upside down.\\nTherefore, the best approach is not to wait until AI leaves you unemployed, but rather proactively embrace it and learn to live with it. As we said already, AI can also create jobs, so a wise move would be to learn to manage AI-based tools. With the advance of AI products, learning to work with them may secure you a job and even promote your career.\\nYour future largely depends on your current and expected income. However, another important factor is the way you manage your finances. Of course, investing in your own or your children’s knowledge is one of the best investments you can ever make. At the same time, if you need some financial cushion to secure your family’s welfare, you should look at the available investment opportunities.\\nAnd this is where artificial intelligence may become your best friend, professional consultant and investment manager. In the recent years, in addition to the traditional banks and financial institutions, we have witnessed the appearance of a totally new and innovative investment system.\\nWe are talking about the blockchain technology and the cryptocurrencies that it supports. Millions of people all over the world have already appreciated the transparency and flexibility of the blockchain networks. By watching the cryptocurrency trends carefully and trading wisely, individual investors have made fortunes within a very short time.\\nNowadays, the cryptocurrency opportunities are open for everyone, not only for the industry experts. There are investment funds running on artificial intelligence that are available for individual investors.\\nWith such funds, you are, on one hand, protected by the blockchain technology. It ensures proper safety of your funds and the security of your transactions. On the other hand, you do not need to be an investment expert to make wise decisions. This is where artificial intelligence is at your service. It analyzes the existing trends on the extremely volatile cryptocurrency market and shows you the best opportunities.\\nThe main point is that we should not regard AI as a threat to our careers and a danger to our well-being. Instead, we should analyze the investment openings created by AI technology that can secure our prosperity. For example, Wolf Coin is using AI technology to create a seamless investment channel for savvy individuals. This robust channel opens great opportunities that investors can use to become new rich kids on the block. Most noteworthy, the low entry cost of $10 has made it one offer that will enjoy a huge buzz. The focus on this new market opening will help people build a solid financial nest egg that will keep them safe even in the face of the storm.\\nWisewolf Fund launching the Wolf Coin focused its effort on creating a great opportunity for people who wish to benefit from cryptocurrency trading but are new to this trend. With artificial intelligence and advanced analytical algorithms, the fund arranges the most favorable conditions for individual investors.\\nMainstream manufacturers, companies, and factories are embracing AI technology to change the mode of their operations. Therefore, it is critical to keep tabs on this reality as it can bring many benefits that cannot be found elsewhere. AI is one of the hottest topics of discussion, however, it is now clear that AI is here to stay. So, people should accept the obvious in order to create the future that they desire. The wisest strategy is to embrace artificial intelligence and let it work to maintain our well-being.\\nFrom a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\\nThe WiseWolf Crypto Fund provides an easy way to enter the cryptocurrency market even for non-techies.\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":142}]},{"cell_type":"code","source":["query = \"What is Machine learning?\"\n","response_text, response_title = get_top_k_text(articles, 5, query)\n","top_k_document_text = \" \".join(response_text)\n","answer = answer_question(query, top_k_document_text)\n","print(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-HeO1R6dYqOo","executionInfo":{"status":"ok","timestamp":1688198108951,"user_tz":-120,"elapsed":2590,"user":{"displayName":"Gururaj Desai","userId":"15324664052380962023"}},"outputId":"26b46b4a-a47e-4d43-b2f4-a72b6903f769"},"execution_count":157,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_fegtvxIcnGd"},"execution_count":null,"outputs":[]}]}